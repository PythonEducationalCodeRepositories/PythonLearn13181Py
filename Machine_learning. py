from typing import TypedDict, List, Union
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, START, END
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains.retrieval_qa.base import RetrievalQA
from pdfplumber.high_level import extract_text
import tempfile
import os
import httpx
import tiktoken
import streamlit as st
from datetime import datetime
import json
from io import BytesIO
from pptx import Presentation
from pptx.util import Pt
from fpdf import FPDF
import spacy
import docx
from reportlab.lib.pagesizes import letter
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
import uuid
import shutil

# Configuration Variables
API_KEY = "your-api-key-here"
BASE_URL = "https://your-base-url-here"

# Available Models List
CHAT_MODELS = [
    "gpt-4o",
    "gpt-4o-mini", 
    "gpt-4-turbo",
    "gpt-4",
    "gpt-3.5-turbo",
    "text-davinci-003",
    "your-custom-model-1",
    "your-custom-model-2"
]

EMBEDDING_MODELS = [
    "text-embedding-ada-002",
    "text-embedding-3-small",
    "text-embedding-3-large",
    "your-custom-embedding-model"
]

# Character Personas
CHARACTER_PERSONAS = {
    "Default Assistant": "You are a helpful and knowledgeable assistant.",
    "Friendly Teacher": "You are a friendly and patient teacher who explains things clearly and encourages learning.",
    "Professional Consultant": "You are a professional business consultant who provides strategic advice and analysis.",
    "Creative Writer": "You are a creative writer who helps with storytelling, creative content, and imaginative ideas.",
    "Technical Expert": "You are a technical expert who provides detailed technical explanations and solutions.",
    "Casual Friend": "You are a casual and friendly companion who chats in a relaxed, conversational manner.",
    "Academic Researcher": "You are an academic researcher who provides scholarly insights and detailed analysis.",
    "Motivational Coach": "You are an enthusiastic motivational coach who inspires and encourages positive action."
}

# Configure
st.set_page_config(page_title='RAG PDF Summarizer Chatbot', layout='wide')

tiktoken_cache_dir = "./token"
os.environ["TIKTOKEN_CACHE_DIR"] = tiktoken_cache_dir

# Create httpx client
@st.cache_resource
def get_http_client():
    return httpx.Client(verify=False, timeout=30.0)

client = get_http_client()

# Load NER model
@st.cache_resource
def load_ner_model():
    try:
        return spacy.load("en_core_web_sm")
    except IOError:
        st.warning("spaCy English model not found. Install with: python -m spacy download en_core_web_sm")
        return None

nlp = load_ner_model()

# Document processing functions
def extract_text_from_file(file, file_type):
    """Extract text from various file types"""
    try:
        if file_type == "pdf":
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                tmp.write(file.getvalue())
                temp_path = tmp.name
            text = extract_text(temp_path)
            os.unlink(temp_path)
            return text
        
        elif file_type == "docx":
            doc = docx.Document(BytesIO(file.getvalue()))
            text = []
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    text.append(paragraph.text)
            return '\n'.join(text)
        
        elif file_type == "txt":
            return file.getvalue().decode('utf-8')
        
        else:
            raise ValueError(f"Unsupported file type: {file_type}")
    
    except Exception as e:
        st.error(f"Error extracting text: {str(e)}")
        return None

# File generation functions
def create_pptx(summary_text: str, filename: str) -> bytes:
    """Create PowerPoint file from text"""
    try:
        prs = Presentation()
        
        # Title slide
        title_slide_layout = prs.slide_layouts[0]
        slide = prs.slides.add_slide(title_slide_layout)
        title = slide.shapes.title
        subtitle = slide.placeholders[1]
        title.text = f"Summary: {filename}"
        subtitle.text = "Generated Summary"
        
        # Content slide
        bullet_slide_layout = prs.slide_layouts[1]
        slide = prs.slides.add_slide(bullet_slide_layout)
        shapes = slide.shapes
        title_shape = shapes.title
        body_shape = shapes.placeholders[1]
        
        title_shape.text = "Key Points"
        tf = body_shape.text_frame
        tf.clear()
        
        # Add bullet points
        lines = [line.strip() for line in summary_text.split('\n') if line.strip()]
        for i, line in enumerate(lines[:10]):  # Limit to 10 points
            if i == 0:
                tf.text = line
            else:
                p = tf.add_paragraph()
                p.text = line
                p.level = 0
                p.font.size = Pt(14)
        
        # Save to bytes
        pptx_io = BytesIO()
        prs.save(pptx_io)
        pptx_io.seek(0)
        return pptx_io.read()
    except Exception as e:
        st.error(f"Error creating PowerPoint: {str(e)}")
        return None

def create_pdf_summary(text: str, filename: str) -> bytes:
    """Create PDF file from text"""
    try:
        pdf = FPDF()
        pdf.add_page()
        pdf.set_auto_page_break(auto=True, margin=15)
        
        # Title
        pdf.set_font("Arial", 'B', 16)
        pdf.cell(0, 10, f'Summary: {filename}', ln=True, align='C')
        pdf.ln(10)
        
        # Content
        pdf.set_font("Arial", size=12)
        for line in text.split('\n'):
            if line.strip():
                try:
                    pdf.multi_cell(0, 8, line.strip())
                    pdf.ln(2)
                except:
                    # Handle special characters
                    clean_line = line.encode('latin1', 'replace').decode('latin1')
                    pdf.multi_cell(0, 8, clean_line)
                    pdf.ln(2)
        
        pdf_output = BytesIO()
        pdf.output(pdf_output)
        pdf_output.seek(0)
        return pdf_output.read()
    except Exception as e:
        st.error(f"Error creating PDF: {str(e)}")
        return None

def create_chat_history_pdf(messages, session_name):
    """Create PDF from chat history"""
    try:
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=letter)
        story = []
        styles = getSampleStyleSheet()
        
        # Title
        title = Paragraph(f"Chat History - {session_name}", styles['Title'])
        story.append(title)
        story.append(Spacer(1, 12))
        
        # Chat messages
        for msg in messages[1:]:  # Skip system message
            if isinstance(msg, HumanMessage):
                user_text = f"<b>Human:</b> {msg.content}"
                story.append(Paragraph(user_text, styles['Normal']))
                story.append(Spacer(1, 6))
            elif isinstance(msg, AIMessage):
                ai_text = f"<b>Assistant:</b> {msg.content}"
                story.append(Paragraph(ai_text, styles['Normal']))
                story.append(Spacer(1, 12))
        
        doc.build(story)
        buffer.seek(0)
        return buffer.read()
    except Exception as e:
        st.error(f"Error creating chat PDF: {str(e)}")
        return None

def extract_entities(text: str) -> dict:
    """Extract named entities using spaCy NER"""
    if not nlp:
        return {}
    
    try:
        # Limit text size to prevent memory issues
        text_sample = text[:50000]  
        doc = nlp(text_sample)
        entities = {}
        
        for ent in doc.ents:
            if ent.label_ not in entities:
                entities[ent.label_] = []
            if ent.text not in entities[ent.label_] and len(entities[ent.label_]) < 10:
                entities[ent.label_].append(ent.text)
        
        return entities
    except Exception as e:
        st.error(f"Error extracting entities: {str(e)}")
        return {}

def format_entities_for_display(entities: dict) -> str:
    """Format entities for nice display"""
    if not entities:
        return "No entities found."
    
    formatted = "## Named Entities Found:\n\n"
    
    entity_labels = {
        'PERSON': 'People',
        'ORG': 'Organizations', 
        'GPE': 'Places',
        'MONEY': 'Money',
        'DATE': 'Dates',
        'TIME': 'Times',
        'PRODUCT': 'Products',
        'EVENT': 'Events',
        'WORK_OF_ART': 'Works of Art',
        'LAW': 'Laws',
        'LANGUAGE': 'Languages'
    }
    
    for label, items in entities.items():
        display_label = entity_labels.get(label, label)
        formatted += f"**{display_label}:**\n"
        for item in items[:5]:  # Limit to 5 per category
            formatted += f"- {item}\n"
        formatted += "\n"
    
    return formatted

# Session management functions
def create_session_structure():
    """Create standard session structure"""
    return {
        "messages": [SystemMessage(content=CHARACTER_PERSONAS["Default Assistant"])],
        "rag_chain": None,
        "rag_ready": False,
        "file_name": None,  # Changed from document_name/pdf_name to file_name
        "session_type": "chat",
        "text_chunks": None,
        "entities": None,
        "character": "Default Assistant",
        "vectordb_path": None
    }

def initialize_session_state():
    """Initialize all session state variables"""
    if "chat_sessions" not in st.session_state:
        st.session_state.chat_sessions = {}
    
    if "current_session_id" not in st.session_state:
        session_id = str(uuid.uuid4())[:8]  # Short ID for display
        st.session_state.current_session_id = session_id
        st.session_state.chat_sessions[session_id] = create_session_structure()
    
    if "selected_chat_model" not in st.session_state:
        st.session_state.selected_chat_model = CHAT_MODELS[0]
    
    if "selected_embedding_model" not in st.session_state:
        st.session_state.selected_embedding_model = EMBEDDING_MODELS[0]
    
    # Initialize model parameters
    if "max_tokens" not in st.session_state:
        st.session_state.max_tokens = 1000
    
    if "temperature" not in st.session_state:
        st.session_state.temperature = 0.7
    
    if "show_ner" not in st.session_state:
        st.session_state.show_ner = False

def get_current_session():
    """Get current session with safety checks"""
    if st.session_state.current_session_id not in st.session_state.chat_sessions:
        # If current session doesn't exist, create it
        st.session_state.chat_sessions[st.session_state.current_session_id] = create_session_structure()
    
    return st.session_state.chat_sessions[st.session_state.current_session_id]

def create_new_session(session_type="chat"):
    """Create a new session"""
    session_id = str(uuid.uuid4())[:8]
    new_session = create_session_structure()
    new_session["session_type"] = session_type
    
    st.session_state.chat_sessions[session_id] = new_session
    st.session_state.current_session_id = session_id
    st.session_state.show_ner = False
    return session_id

def delete_session(session_id):
    """Delete a session with cleanup"""
    if len(st.session_state.chat_sessions) > 1 and session_id in st.session_state.chat_sessions:
        # Clean up vectordb
        session = st.session_state.chat_sessions[session_id]
        if session.get("vectordb_path") and os.path.exists(session["vectordb_path"]):
            try:
                shutil.rmtree(session["vectordb_path"])
            except:
                pass
        
        del st.session_state.chat_sessions[session_id]
        
        if st.session_state.current_session_id == session_id:
            st.session_state.current_session_id = list(st.session_state.chat_sessions.keys())[0]

# Helper functions
def display_chat(messages):
    """Display chat messages"""
    for msg in messages[1:]:  # Skip system message
        if isinstance(msg, HumanMessage):
            with st.chat_message("user"):
                st.write(msg.content)
        elif isinstance(msg, AIMessage):
            with st.chat_message("assistant"):
                st.write(msg.content)

def generate_document_summary(text_chunks, character_persona):
    """Generate summary of document chunks"""
    try:
        chat = ChatOpenAI(
            base_url=BASE_URL,
            api_key=API_KEY,
            model=st.session_state.selected_chat_model,
            max_tokens=st.session_state.max_tokens,
            temperature=st.session_state.temperature,
            http_client=client
        )
        
        combined_text = "\n".join(text_chunks[:10])
        summary_prompt = f"""
        {character_persona}
        
        Please provide a comprehensive summary of the following document content:
        
        {combined_text}
        """
        
        response = chat.invoke([HumanMessage(content=summary_prompt)])
        return response.content
    except Exception as e:
        st.error(f"Error generating summary: {str(e)}")
        return None

def process_document(uploaded_file):
    """Process uploaded document and create RAG chain"""
    try:
        # Extract text
        file_type = uploaded_file.name.split('.')[-1].lower()
        raw_text = extract_text_from_file(uploaded_file, file_type)
        
        if not raw_text or len(raw_text.strip()) < 10:
            st.error("Could not extract sufficient text from document")
            return False
        
        # Get current session
        current_session = get_current_session()
        
        # Split text into chunks
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000, 
            chunk_overlap=200,
            separators=["\n\n", "\n", " ", ""]
        )
        chunks = text_splitter.split_text(raw_text)
        
        if not chunks:
            st.error("Could not create text chunks from document")
            return False
        
        # Extract entities
        entities = extract_entities(raw_text)
        
        # Create unique vectordb path
        vectordb_path = f"./chroma_index_{st.session_state.current_session_id}"
        
        # Create embeddings
        embedding_model = OpenAIEmbeddings(
            base_url=BASE_URL,
            model=st.session_state.selected_embedding_model,
            api_key=API_KEY,
            http_client=client
        )
        
        # Create vector store
        vectordb = Chroma.from_texts(
            chunks, 
            embedding_model, 
            persist_directory=vectordb_path
        )
        vectordb.persist()
        
        # Create LLM
        llm = ChatOpenAI(
            base_url=BASE_URL,
            model=st.session_state.selected_chat_model,
            max_tokens=st.session_state.max_tokens,
            temperature=st.session_state.temperature,
            api_key=API_KEY,
            http_client=client
        )
        
        # Create RAG chain
        retriever = vectordb.as_retriever(search_kwargs={"k": 3})
        rag_chain = RetrievalQA.from_chain_type(
            llm=llm, 
            retriever=retriever, 
            return_source_documents=True
        )
        
        # Update session
        current_session.update({
            "rag_chain": rag_chain,
            "rag_ready": True,
            "file_name": uploaded_file.name,  # Use consistent key name
            "text_chunks": chunks,
            "entities": entities,
            "vectordb_path": vectordb_path,
            "session_type": "document"
        })
        
        return True
        
    except Exception as e:
        st.error(f"Error processing document: {str(e)}")
        return False

# Initialize
initialize_session_state()

# Main UI
st.title("AI RAG Chat Assistant")

# Sidebar
with st.sidebar:
    # Add TEAM A BBSR Logo at the top
    st.markdown("""
        <div style='text-align: center; padding: 10px; margin-bottom: 20px; background-color: #f0f2f6; border-radius: 10px;'>
            <h2 style='color: #1f77b4; margin: 0; font-weight: bold;'>🚀 TEAM A BBSR</h2>
            <p style='color: #666; margin: 5px 0 0 0; font-size: 12px;'>AI Solutions & Innovation</p>
        </div>
    """, unsafe_allow_html=True)
    
    st.header("Settings")
    
    # Model Selection
    st.subheader("Models")
    st.session_state.selected_chat_model = st.selectbox(
        "Chat Model:",
        CHAT_MODELS,
        index=CHAT_MODELS.index(st.session_state.selected_chat_model)
    )
    
    st.session_state.selected_embedding_model = st.selectbox(
        "Embedding Model:",
        EMBEDDING_MODELS,
        index=EMBEDDING_MODELS.index(st.session_state.selected_embedding_model)
    )
    
    # Model Parameters - Add sliders for tokens and temperature
    st.subheader("Model Parameters")
    
    # Max Tokens Slider
    st.session_state.max_tokens = st.slider(
        "Max Tokens:",
        min_value=50,
        max_value=4000,
        value=st.session_state.max_tokens,
        step=50,
        help="Maximum number of tokens to generate"
    )
    
    # Temperature Slider
    st.session_state.temperature = st.slider(
        "Temperature:",
        min_value=0.0,
        max_value=2.0,
        value=st.session_state.temperature,
        step=0.1,
        help="Controls randomness: 0.0 = deterministic, 2.0 = very creative"
    )
    
    # Display current values
    st.caption(f"Current: {st.session_state.max_tokens} tokens, {st.session_state.temperature} temperature")
    
    # Character Selection
    st.subheader("Character")
    current_session = get_current_session()
    selected_character = st.selectbox(
        "Select Character:",
        list(CHARACTER_PERSONAS.keys()),
        index=list(CHARACTER_PERSONAS.keys()).index(current_session["character"])
    )
    
    # Update character if changed
    if current_session["character"] != selected_character:
        current_session["character"] = selected_character
        current_session["messages"][0] = SystemMessage(content=CHARACTER_PERSONAS[selected_character])
    
    st.divider()
    
    # Document Upload
    st.subheader("Document Upload")
    uploaded_file = st.file_uploader(
        "Upload Document", 
        type=["pdf", "docx", "txt"]
    )
    
    if uploaded_file:
        if st.button("Process Document"):
            with st.spinner("Processing document..."):
                # Create new document session
                create_new_session("document")
                
                if process_document(uploaded_file):
                    st.success("Document processed successfully!")
                else:
                    st.error("Failed to process document")
    
    # Document Actions
    current_session = get_current_session()
    if current_session["rag_ready"]:
        st.subheader("Document Tools")
        
        # Download format
        download_format = st.selectbox("Format:", ["txt", "pdf", "pptx"])
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("Summary"):
                with st.spinner("Generating..."):
                    character_persona = CHARACTER_PERSONAS[current_session["character"]]
                    summary = generate_document_summary(current_session["text_chunks"], character_persona)
                    
                    if summary:
                        filename = current_session["file_name"]
                        if filename and '.' in filename:
                            filename = filename.rsplit('.', 1)[0]
                        
                        if download_format == "txt":
                            st.download_button(
                                "Download TXT",
                                data=summary,
                                file_name=f"{filename}_summary.txt",
                                mime="text/plain"
                            )
                        elif download_format == "pdf":
                            pdf_data = create_pdf_summary(summary, filename)
                            if pdf_data:
                                st.download_button(
                                    "Download PDF",
                                    data=pdf_data,
                                    file_name=f"{filename}_summary.pdf",
                                    mime="application/pdf"
                                )
                        elif download_format == "pptx":
                            pptx_data = create_pptx(summary, filename)
                            if pptx_data:
                                st.download_button(
                                    "Download PPTX",
                                    data=pptx_data,
                                    file_name=f"{filename}_summary.pptx",
                                    mime="application/vnd.openxmlformats-officedocument.presentationml.presentation"
                                )
        
        with col2:
            if st.button("NER"):
                st.session_state.show_ner = not st.session_state.show_ner
    
    st.divider()
    
    # Session Management
    st.subheader("Sessions")
    
    if st.button("New Chat"):
        create_new_session("chat")
    
    # Display sessions
    for session_id in list(st.session_state.chat_sessions.keys()):
        session = st.session_state.chat_sessions[session_id]
        
        # Session display name
        file_name = session.get("file_name")
        if file_name:
            display_name = f"📄 {file_name[:20]}..."
        else:
            display_name = f"💬 Chat {session_id[:4]}"
        
        col1, col2, col3 = st.columns([3, 1, 1])
        
        with col1:
            if st.button(
                display_name,
                key=f"session_{session_id}",
                type="primary" if session_id == st.session_state.current_session_id else "secondary"
            ):
                st.session_state.current_session_id = session_id
                st.session_state.show_ner = False
        
        with col2:
            # Download chat history
            if len(session["messages"]) > 1:
                chat_pdf = create_chat_history_pdf(session["messages"], session_id[:4])
                if chat_pdf:
                    st.download_button(
                        "D",
                        data=chat_pdf,
                        file_name=f"chat_{session_id[:4]}.pdf",
                        mime="application/pdf",
                        key=f"dl_{session_id}",
                        help="Download chat"
                    )
        
        with col3:
            if st.button("X", key=f"del_{session_id}", help="Delete"):
                delete_session(session_id)
    
    if st.button("Clear All"):
        # Clean up vectordbs
        for session in st.session_state.chat_sessions.values():
            if session.get("vectordb_path") and os.path.exists(session["vectordb_path"]):
                try:
                    shutil.rmtree(session["vectordb_path"])
                except:
                    pass
        
        st.session_state.chat_sessions = {}
        create_new_session("chat")
        st.session_state.show_ner = False

# Main content
current_session = get_current_session()

# Display session info
file_name = current_session.get("file_name")
if file_name:
    st.info(f"Document Session: **{file_name}** | Character: **{current_session['character']}** | Tokens: **{st.session_state.max_tokens}** | Temp: **{st.session_state.temperature}**")
else:
    st.info(f"Chat Session | Character: **{current_session['character']}** | Tokens: **{st.session_state.max_tokens}** | Temp: **{st.session_state.temperature}**")

# Display NER results
if st.session_state.show_ner and current_session.get("entities"):
    with st.expander("Named Entity Recognition Results", expanded=True):
        entity_display = format_entities_for_display(current_session["entities"])
        st.markdown(entity_display)

# Display chat history
display_chat(current_session["messages"])

# Chat input
if current_session["rag_ready"]:
    # Document chat mode
    if prompt := st.chat_input("Ask about the document..."):
        current_session["messages"].append(HumanMessage(content=prompt))
        with st.chat_message("user"):
            st.write(prompt)
        
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                try:
                    character_context = CHARACTER_PERSONAS[current_session["character"]]
                    enhanced_prompt = f"{character_context}\n\nUser question: {prompt}"
                    
                    result = current_session["rag_chain"].invoke({"query": enhanced_prompt})
                    answer = result["result"]
                    
                    current_session["messages"].append(AIMessage(content=answer))
                    st.write(answer)
                    
                except Exception as e:
                    error_msg = f"Error: {str(e)}"
                    current_session["messages"].append(AIMessage(content=error_msg))
                    st.error(error_msg)
else:
    # Regular chat mode
    if prompt := st.chat_input("Ask me anything..."):
        current_session["messages"].append(HumanMessage(content=prompt))
        with st.chat_message("user"):
            st.write(prompt)
        
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                try:
                    chat = ChatOpenAI(
                        base_url=BASE_URL,
                        api_key=API_KEY,
                        temperature=st.session_state.temperature,
                        max_tokens=st.session_state.max_tokens,
                        model=st.session_state.selected_chat_model,
                        http_client=client
                    )

                    class AgentState(TypedDict):
                        messages: List[Union[HumanMessage, AIMessage, SystemMessage]]

                    def chat_node(state: AgentState) -> AgentState:
                        character_context = CHARACTER_PERSONAS[current_session["character"]]
                        enhanced_messages = state["messages"].copy()
                        enhanced_messages[0] = SystemMessage(content=character_context)
                        
                        response = chat.invoke(enhanced_messages)
                        state["messages"].append(AIMessage(content=response.content))
                        return state

                    graph = StateGraph(AgentState)
                    graph.add_node("chat", chat_node)
                    graph.add_edge(START, "chat")
                    graph.add_edge("chat", END)
                    agent = graph.compile()

                    state_input = {"messages": current_session["messages"].copy()}
                    result = agent.invoke(state_input)
                    response = result["messages"][-1].content

                    current_session["messages"].append(AIMessage(content=response))
                    st.write(response)
                    
                except Exception as e:
                    error_msg = f"Error: {str(e)}"
                    current_session["messages"].append(AIMessage(content=error_msg))
                    st.error(error_msg)
