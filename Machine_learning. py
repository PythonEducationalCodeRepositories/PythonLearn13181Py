import os
from dotenv import load_dotenv

load_dotenv()

API_KEY = os.getenv("API_KEY", "your-api-key-here")
BASE_URL = os.getenv("BASE_URL", "https://your-base-url-here")

CHAT_MODELS = os.getenv("CHAT_MODELS", "gpt-4o,gpt-4o-mini").split(",")
EMBEDDING_MODELS = os.getenv("EMBEDDING_MODELS", "text-embedding-ada-002").split(",")

CHARACTER_PERSONAS = {
    "Default Assistant": "You are a helpful and knowledgeable assistant.",
    "Friendly Teacher": "You are a friendly and patient teacher who explains things clearly and encourages learning.",
    "Professional Consultant": "You are a professional business consultant who provides strategic advice and analysis.",
    "Creative Writer": "You are a creative writer who helps with storytelling, creative content, and imaginative ideas.",
    "Technical Expert": "You are a technical expert who provides detailed technical explanations and solutions.",
    "Casual Friend": "You are a casual and friendly companion who chats in a relaxed, conversational manner.",
    "Academic Researcher": "You are an academic researcher who provides scholarly insights and detailed analysis.",
    "Motivational Coach": "You are an enthusiastic motivational coach who inspires and encourages positive action."
}















from .core import ModelManager, generate_summary, extract_entities, format_entities_for_display
from .docs import extract_text_from_file
from .gen_files import create_pptx, create_pdf, create_chat_history_pdf
from .session import initialize_session_state, get_current_session, create_new_session, delete_session, display_chat

__all__ = [
    'ModelManager', 'generate_summary', 'extract_entities', 'format_entities_for_display',
    'extract_text_from_file',
    'create_pptx', 'create_pdf', 'create_chat_history_pdf',
    'initialize_session_state', 'get_current_session', 'create_new_session', 'delete_session', 'display_chat'
]












from typing import List, Dict, Union
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains.retrieval_qa.base import RetrievalQA
from langchain.text_splitter import RecursiveCharacterTextSplitter
import httpx
import spacy

# Load NER model
try:
    nlp = spacy.load("en_core_web_sm")
except IOError:
    nlp = None

class ModelManager:
    def __init__(self, api_key: str, base_url: str, model_name: str, embedding_model_name: str):
        self.api_key = api_key
        self.base_url = base_url
        self.model_name = model_name
        self.embedding_model_name = embedding_model_name
        self.client = httpx.Client(verify=False)
        
    def create_embedding(self):
        return OpenAIEmbeddings(
            api_key=self.api_key,
            model=self.embedding_model_name,
            base_url=self.base_url,
            http_client=self.client
        )

    def create_llm(self, temperature: float = 0.7, max_tokens: int = 1000):
        return ChatOpenAI(
            api_key=self.api_key,
            model=self.model_name,
            temperature=temperature,
            max_tokens=max_tokens,
            base_url=self.base_url,
            http_client=self.client
        )

    def create_rag_chain(self, texts: List[str], temperature: float = 0.7, max_tokens: int = 1000, persist_dir: str = "./chroma_index"):
        embedding = self.create_embedding()
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
        chunks = text_splitter.split_text("\n\n".join(texts))
        
        vectordb = Chroma.from_texts(chunks, embedding, persist_directory=persist_dir)
        vectordb.persist()
        
        llm = self.create_llm(temperature, max_tokens)
        retriever = vectordb.as_retriever()
        return RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)

def generate_summary(text_chunks: List[str], model_manager: ModelManager, character_persona: str) -> str:
    """Generate summary of document chunks"""
    llm = model_manager.create_llm()
    combined_text = "\n".join(text_chunks[:10])
    summary_prompt = f"""
    {character_persona}
    
    Please provide a comprehensive summary of the following document content:
    
    {combined_text}
    """
    
    response = llm.invoke([HumanMessage(content=summary_prompt)])
    return response.content

def extract_entities(text: str) -> Dict:
    """Extract named entities using spaCy NER"""
    if not nlp:
        return {}
    
    doc = nlp(text[:50000])  # Limit text size
    entities = {}
    
    for ent in doc.ents:
        if ent.label_ not in entities:
            entities[ent.label_] = []
        if ent.text not in entities[ent.label_] and len(entities[ent.label_]) < 10:
            entities[ent.label_].append(ent.text)
    
    return entities

def format_entities_for_display(entities: Dict) -> str:
    """Format entities for nice display"""
    if not entities:
        return "No entities found."
    
    formatted = "## Named Entities Found:\n\n"
    
    entity_labels = {
        'PERSON': 'People', 'ORG': 'Organizations', 'GPE': 'Places',
        'MONEY': 'Money', 'DATE': 'Dates', 'TIME': 'Times',
        'PRODUCT': 'Products', 'EVENT': 'Events', 'WORK_OF_ART': 'Works of Art',
        'LAW': 'Laws', 'LANGUAGE': 'Languages'
    }
    
    for label, items in entities.items():
        display_label = entity_labels.get(label, label)
        formatted += f"**{display_label}:**\n"
        for item in items[:5]:
            formatted += f"- {item}\n"
        formatted += "\n"
    
    return formatted












import tempfile
import os
from pdfplumber.high_level import extract_text
import docx

def extract_text_from_file(file, file_type: str) -> str:
    """Extract text from various file types"""
    if file_type == "pdf":
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(file.read())
            temp_path = tmp.name
        text = extract_text(temp_path)
        os.unlink(temp_path)
        return text
    
    elif file_type == "docx":
        doc = docx.Document(file)
        text = []
        for paragraph in doc.paragraphs:
            text.append(paragraph.text)
        return '\n'.join(text)
    
    elif file_type == "txt":
        return file.read().decode('utf-8')
    
    else:
        raise ValueError(f"Unsupported file type: {file_type}")










from typing import List, Union
from io import BytesIO
from pptx import Presentation
from pptx.util import Pt
from fpdf import FPDF
from reportlab.lib.pagesizes import letter
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

def create_pptx(summary_text: str, filename: str) -> bytes:
    """Create PowerPoint file from text"""
    prs = Presentation()
    
    # Title slide
    title_slide_layout = prs.slide_layouts[0]
    slide = prs.slides.add_slide(title_slide_layout)
    title = slide.shapes.title
    subtitle = slide.placeholders[1]
    title.text = f"Summary: {filename}"
    subtitle.text = "Generated Summary"
    
    # Content slide
    bullet_slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(bullet_slide_layout)
    shapes = slide.shapes
    title_shape = shapes.title
    body_shape = shapes.placeholders[1]
    
    title_shape.text = "Key Points"
    tf = body_shape.text_frame
    tf.clear()
    
    lines = [line.strip() for line in summary_text.split('\n') if line.strip()]
    for i, line in enumerate(lines[:10]):
        if i == 0:
            tf.text = line
        else:
            p = tf.add_paragraph()
            p.text = line
            p.level = 0
            p.font.size = Pt(14)
    
    pptx_io = BytesIO()
    prs.save(pptx_io)
    pptx_io.seek(0)
    return pptx_io.read()

def create_pdf(text: str, filename: str) -> bytes:
    """Create PDF file from text"""
    pdf = FPDF()
    pdf.add_page()
    pdf.set_auto_page_break(auto=True, margin=15)
    
    pdf.set_font("Arial", 'B', 16)
    pdf.cell(0, 10, f'Summary: {filename}', ln=True, align='C')
    pdf.ln(10)
    
    pdf.set_font("Arial", size=12)
    for line in text.split('\n'):
        if line.strip():
            pdf.multi_cell(0, 8, line.strip())
            pdf.ln(2)
    
    pdf_output = BytesIO()
    pdf.output(pdf_output)
    pdf_output.seek(0)
    return pdf_output.read()

def create_chat_history_pdf(messages: List[Union[HumanMessage, AIMessage, SystemMessage]], session_id: str) -> bytes:
    """Create PDF from chat history"""
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter)
    story = []
    styles = getSampleStyleSheet()
    
    title = Paragraph(f"Chat History - {session_id}", styles['Title'])
    story.append(title)
    story.append(Spacer(1, 12))
    
    for msg in messages[1:]:  # Skip system message
        if isinstance(msg, HumanMessage):
            user_text = f"<b>Human:</b> {msg.content}"
            story.append(Paragraph(user_text, styles['Normal']))
            story.append(Spacer(1, 6))
        elif isinstance(msg, AIMessage):
            ai_text = f"<b>Assistant:</b> {msg.content}"
            story.append(Paragraph(ai_text, styles['Normal']))
            story.append(Spacer(1, 12))
    
    doc.build(story)
    buffer.seek(0)
    return buffer.read()














import streamlit as st
from datetime import datetime
from typing import List, Union
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage

def initialize_session_state():
    """Initialize all session state variables"""
    if "chat_sessions" not in st.session_state:
        st.session_state.chat_sessions = {}
    
    if "current_session_id" not in st.session_state:
        session_id = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        st.session_state.current_session_id = session_id
        st.session_state.chat_sessions[session_id] = {
            "messages": [SystemMessage(content="You are a helpful assistant.")],
            "rag_chain": None,
            "rag_ready": False,
            "pdf_name": None,
            "session_type": "chat",
            "text_chunks": None,
            "entities": None,
            "all_doc_entities": None,
            "character": "Default Assistant"
        }
    
    if "show_ner" not in st.session_state:
        st.session_state.show_ner = False

def get_current_session():
    """Get current session"""
    return st.session_state.chat_sessions[st.session_state.current_session_id]

def create_new_session(session_type="chat"):
    """Create a new session"""
    session_id = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.session_state.chat_sessions[session_id] = {
        "messages": [SystemMessage(content="You are a helpful assistant.")],
        "rag_chain": None,
        "rag_ready": False,
        "pdf_name": None,
        "session_type": session_type,
        "text_chunks": None,
        "entities": None,
        "all_doc_entities": None,
        "character": "Default Assistant"
    }
    st.session_state.current_session_id = session_id
    return session_id

def delete_session(session_id):
    """Delete a session"""
    if len(st.session_state.chat_sessions) > 1:
        del st.session_state.chat_sessions[session_id]
        if st.session_state.current_session_id == session_id:
            st.session_state.current_session_id = list(st.session_state.chat_sessions.keys())[0]

def display_chat(messages: List[Union[HumanMessage, AIMessage, SystemMessage]]):
    """Display chat messages"""
    for msg in messages[1:]:  # Skip system message
        if isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)

















import streamlit as st
from typing import TypedDict, List, Union
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, START, END

# Import configuration and utilities
import config
from utils import (
    ModelManager, generate_summary, extract_entities, format_entities_for_display,
    extract_text_from_file, create_pptx, create_pdf, create_chat_history_pdf,
    initialize_session_state, get_current_session, create_new_session, delete_session, display_chat
)

# Configure Streamlit
st.set_page_config(page_title='RAG PDF Summarizer Chatbot', layout='wide')

# Initialize session state
initialize_session_state()

# Sidebar
with st.sidebar:
    # TEAM A BBSR branding
    st.markdown(
        "<h2 style='text-align:center; color:#004080; margin-bottom:0;'>TEAM A BBSR</h2>"
        "<h4 style='text-align:center; margin-top:2px;'>Multi-Document RAG Chatbot</h4><hr>",
        unsafe_allow_html=True,
    )
    
    st.title("AI Chat Assistant")
    
    # Model Selection
    st.subheader("Model Settings")
    selected_chat_model = st.selectbox("Chat Model:", config.CHAT_MODELS)
    selected_embedding_model = st.selectbox("Embedding Model:", config.EMBEDDING_MODELS)
    
    # Character Selection
    st.subheader("Character Persona")
    current_session = get_current_session()
    selected_character = st.selectbox(
        "Select Character:",
        list(config.CHARACTER_PERSONAS.keys()),
        index=list(config.CHARACTER_PERSONAS.keys()).index(current_session.get("character", "Default Assistant"))
    )
    
    if current_session["character"] != selected_character:
        current_session["character"] = selected_character
        current_session["messages"][0] = SystemMessage(content=config.CHARACTER_PERSONAS[selected_character])
    
    st.divider()
    
    # Multi-Document Upload Section
    st.subheader("Document Upload")
    uploaded_files = st.file_uploader(
        "Upload Documents for Analysis (PDF/DOCX/TXT)", 
        type=["pdf", "docx", "txt"],
        accept_multiple_files=True,
        key="multifile"
    )
    
    if uploaded_files:
        if st.button("Process Documents"):
            create_new_session("document")
            current_session = get_current_session()
            current_session["pdf_name"] = ", ".join([f.name for f in uploaded_files])
            
            with st.spinner("Processing documents..."):
                try:
                    # Create model manager
                    model_manager = ModelManager(
                        config.API_KEY, config.BASE_URL, 
                        selected_chat_model, selected_embedding_model
                    )
                    
                    all_texts = []
                    all_entities = {}
                    
                    for file in uploaded_files:
                        file_type = file.name.split('.')[-1].lower()
                        text = extract_text_from_file(file, file_type)
                        all_texts.append(text)
                        
                        # NER per document
                        entities = extract_entities(text)
                        all_entities[file.name] = entities
                    
                    # Create RAG chain with all documents
                    rag_chain = model_manager.create_rag_chain(all_texts)
                    
                    current_session["rag_chain"] = rag_chain
                    current_session["rag_ready"] = True
                    current_session["text_chunks"] = all_texts
                    current_session["all_doc_entities"] = all_entities
                    
                    st.success("All documents processed and cross-indexed successfully!")
                    st.rerun()
                except Exception as e:
                    st.error(f"Error processing documents: {str(e)}")
    
    # Document Actions
    current_session = get_current_session()
    if current_session["rag_ready"]:
        st.subheader("Document Actions")
        
        download_format = st.selectbox("Download Format:", ["txt", "pdf", "pptx"])
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("Generate Summary"):
                with st.spinner("Generating summary..."):
                    model_manager = ModelManager(
                        config.API_KEY, config.BASE_URL,
                        selected_chat_model, selected_embedding_model
                    )
                    character_persona = config.CHARACTER_PERSONAS[current_session["character"]]
                    summary = generate_summary(current_session["text_chunks"], model_manager, character_persona)
                    filename = current_session["pdf_name"].replace(", ", "_").replace(".pdf", "").replace(".docx", "").replace(".txt", "")
                    
                    if download_format == "txt":
                        st.download_button("Download TXT", data=summary, file_name=f"{filename}_summary.txt", mime="text/plain")
                    elif download_format == "pdf":
                        pdf_data = create_pdf(summary, filename)
                        st.download_button("Download PDF", data=pdf_data, file_name=f"{filename}_summary.pdf", mime="application/pdf")
                    elif download_format == "pptx":
                        pptx_data = create_pptx(summary, filename)
                        st.download_button("Download PPTX", data=pptx_data, file_name=f"{filename}_summary.pptx", mime="application/vnd.openxmlformats-officedocument.presentationml.presentation")
        
        with col2:
            if st.button("Show NER"):
                st.session_state.show_ner = not st.session_state.show_ner
                st.rerun()
    
    st.divider()
    
    # Session Management (rest of sidebar code...)
    # [Include your existing session management code here]

# Main Chat Interface (rest of main area code...)
# [Include your existing main chat interface code here]



