from typing import TypedDict, List, Union
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, START, END
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains.retrieval_qa.base import RetrievalQA
from pdfplumber.high_level import extract_text
import tempfile
import os
import httpx
import tiktoken
import streamlit as st
from datetime import datetime
import json
from io import BytesIO
from pptx import Presentation
from pptx.util import Pt
from fpdf import FPDF
import spacy
import docx
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer

# Configuration Variables
API_KEY = "your-api-key-here"
BASE_URL = "https://your-base-url-here"

# Available Models List
CHAT_MODELS = [
    "gpt-4o",
    "gpt-4o-mini", 
    "gpt-4-turbo",
    "gpt-4",
    "gpt-3.5-turbo",
    "text-davinci-003",
    "your-custom-model-1",
    "your-custom-model-2"
]

EMBEDDING_MODELS = [
    "text-embedding-ada-002",
    "text-embedding-3-small",
    "text-embedding-3-large",
    "your-custom-embedding-model"
]

# Character Personas
CHARACTER_PERSONAS = {
    "Default Assistant": "You are a helpful and knowledgeable assistant.",
    "Friendly Teacher": "You are a friendly and patient teacher who explains things clearly and encourages learning.",
    "Professional Consultant": "You are a professional business consultant who provides strategic advice and analysis.",
    "Creative Writer": "You are a creative writer who helps with storytelling, creative content, and imaginative ideas.",
    "Technical Expert": "You are a technical expert who provides detailed technical explanations and solutions.",
    "Casual Friend": "You are a casual and friendly companion who chats in a relaxed, conversational manner.",
    "Academic Researcher": "You are an academic researcher who provides scholarly insights and detailed analysis.",
    "Motivational Coach": "You are an enthusiastic motivational coach who inspires and encourages positive action."
}

# Configure
st.set_page_config(page_title='RAG PDF Summarizer Chatbot', layout='wide')

tiktoken_cache_dir = "./token"
os.environ["TIKTOKEN_CACHE_DIR"] = tiktoken_cache_dir
client = httpx.Client(verify=False)

# Load NER model
@st.cache_resource
def load_ner_model():
    try:
        return spacy.load("en_core_web_sm")
    except IOError:
        st.error("Please install spaCy English model: python -m spacy download en_core_web_sm")
        return None

nlp = load_ner_model()

# Document processing functions
def extract_text_from_file(file, file_type):
    """Extract text from various file types"""
    if file_type == "pdf":
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(file.read())
            temp_path = tmp.name
        text = extract_text(temp_path)
        os.unlink(temp_path)
        return text
    
    elif file_type == "docx":
        doc = docx.Document(file)
        text = []
        for paragraph in doc.paragraphs:
            text.append(paragraph.text)
        return '\n'.join(text)
    
    elif file_type == "txt":
        return file.read().decode('utf-8')
    
    else:
        raise ValueError(f"Unsupported file type: {file_type}")

# File generation functions
def create_pptx(summary_text: str, filename: str) -> bytes:
    """Create PowerPoint file from text"""
    prs = Presentation()
    
    # Title slide
    title_slide_layout = prs.slide_layouts[0]
    slide = prs.slides.add_slide(title_slide_layout)
    title = slide.shapes.title
    subtitle = slide.placeholders[1]
    title.text = f"Summary: {filename}"
    subtitle.text = "Generated Summary"
    
    # Content slide
    bullet_slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(bullet_slide_layout)
    shapes = slide.shapes
    title_shape = shapes.title
    body_shape = shapes.placeholders[1]
    
    title_shape.text = "Key Points"
    tf = body_shape.text_frame
    tf.clear()
    
    # Add bullet points
    lines = [line.strip() for line in summary_text.split('\n') if line.strip()]
    for i, line in enumerate(lines[:10]):  # Limit to 10 points
        if i == 0:
            tf.text = line
        else:
            p = tf.add_paragraph()
            p.text = line
            p.level = 0
            p.font.size = Pt(14)
    
    # Save to bytes
    pptx_io = BytesIO()
    prs.save(pptx_io)
    pptx_io.seek(0)
    return pptx_io.read()

def create_pdf(text: str, filename: str) -> bytes:
    """Create PDF file from text"""
    pdf = FPDF()
    pdf.add_page()
    pdf.set_auto_page_break(auto=True, margin=15)
    
    # Title
    pdf.set_font("Arial", 'B', 16)
    pdf.cell(0, 10, f'Summary: {filename}', ln=True, align='C')
    pdf.ln(10)
    
    # Content
    pdf.set_font("Arial", size=12)
    for line in text.split('\n'):
        if line.strip():
            pdf.multi_cell(0, 8, line.strip())
            pdf.ln(2)
    
    pdf_output = BytesIO()
    pdf.output(pdf_output)
    pdf_output.seek(0)
    return pdf_output.read()

def create_chat_history_pdf(messages: List[Union[HumanMessage, AIMessage, SystemMessage]], session_id: str) -> bytes:
    """Create PDF from chat history"""
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=letter)
    story = []
    styles = getSampleStyleSheet()
    
    # Title
    title = Paragraph(f"Chat History - {session_id}", styles['Title'])
    story.append(title)
    story.append(Spacer(1, 12))
    
    # Chat messages
    for msg in messages[1:]:  # Skip system message
        if isinstance(msg, HumanMessage):
            user_text = f"<b>Human:</b> {msg.content}"
            story.append(Paragraph(user_text, styles['Normal']))
            story.append(Spacer(1, 6))
        elif isinstance(msg, AIMessage):
            ai_text = f"<b>Assistant:</b> {msg.content}"
            story.append(Paragraph(ai_text, styles['Normal']))
            story.append(Spacer(1, 12))
    
    doc.build(story)
    buffer.seek(0)
    return buffer.read()

def extract_entities(text: str) -> dict:
    """Extract named entities using spaCy NER"""
    if not nlp:
        return {}
    
    doc = nlp(text)
    entities = {}
    
    for ent in doc.ents:
        if ent.label_ not in entities:
            entities[ent.label_] = []
        if ent.text not in entities[ent.label_]:
            entities[ent.label_].append(ent.text)
    
    return entities

def format_entities_for_display(entities: dict) -> str:
    """Format entities for nice display"""
    if not entities:
        return "No entities found."
    
    formatted = "## Named Entities Found:\n\n"
    
    entity_labels = {
        'PERSON': 'People',
        'ORG': 'Organizations', 
        'GPE': 'Places',
        'MONEY': 'Money',
        'DATE': 'Dates',
        'TIME': 'Times',
        'PRODUCT': 'Products',
        'EVENT': 'Events',
        'WORK_OF_ART': 'Works of Art',
        'LAW': 'Laws',
        'LANGUAGE': 'Languages'
    }
    
    for label, items in entities.items():
        display_label = entity_labels.get(label, label)
        formatted += f"**{display_label}:**\n"
        for item in items[:5]:  # Limit to 5 per category
            formatted += f"- {item}\n"
        formatted += "\n"
    
    return formatted

# Initialize session state
def initialize_session_state():
    if "chat_sessions" not in st.session_state:
        st.session_state.chat_sessions = {}
    
    if "current_session_id" not in st.session_state:
        session_id = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        st.session_state.current_session_id = session_id
        st.session_state.chat_sessions[session_id] = {
            "messages": [SystemMessage(content="You are a helpful assistant.")],
            "rag_chain": None,
            "rag_ready": False,
            "pdf_name": None,
            "session_type": "chat",
            "text_chunks": None,
            "entities": None,
            "all_doc_entities": None,
            "character": "Default Assistant"
        }
    
    if "selected_chat_model" not in st.session_state:
        st.session_state.selected_chat_model = CHAT_MODELS[0]
    
    if "selected_embedding_model" not in st.session_state:
        st.session_state.selected_embedding_model = EMBEDDING_MODELS[0]
    
    if "show_ner" not in st.session_state:
        st.session_state.show_ner = False

def get_current_session():
    return st.session_state.chat_sessions[st.session_state.current_session_id]

def create_new_session(session_type="chat"):
    session_id = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.session_state.chat_sessions[session_id] = {
        "messages": [SystemMessage(content="You are a helpful assistant.")],
        "rag_chain": None,
        "rag_ready": False,
        "pdf_name": None,
        "session_type": session_type,
        "text_chunks": None,
        "entities": None,
        "all_doc_entities": None,
        "character": "Default Assistant"
    }
    st.session_state.current_session_id = session_id
    return session_id

def delete_session(session_id):
    if len(st.session_state.chat_sessions) > 1:
        del st.session_state.chat_sessions[session_id]
        if st.session_state.current_session_id == session_id:
            st.session_state.current_session_id = list(st.session_state.chat_sessions.keys())[0]

# Helper to display chat messages
def display_chat(messages: List[Union[HumanMessage, AIMessage, SystemMessage]]):
    for msg in messages[1:]:  # Skip system message
        if isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)

# Generate PDF Summary
def generate_pdf_summary(text_chunks):
    chat = ChatOpenAI(
        base_url=BASE_URL,
        api_key=API_KEY,
        model=st.session_state.selected_chat_model,
        http_client=client
    )
    
    combined_text = "\n".join(text_chunks[:10])  # Limit for summary
    summary_prompt = f"Please provide a comprehensive summary of the following document content:\n\n{combined_text}"
    
    response = chat.invoke([HumanMessage(content=summary_prompt)])
    return response.content

# Initialize
initialize_session_state()

# Sidebar
with st.sidebar:
    # Add TEAM A BBSR branding
    st.markdown(
        "<h2 style='text-align:center; color:#004080; margin-bottom:0;'>TEAM A BBSR</h2>"
        "<h4 style='text-align:center; margin-top:2px;'>Multi-Document RAG Chatbot</h4><hr>",
        unsafe_allow_html=True,
    )
    
    st.title("AI Chat Assistant")
    
    # Model Selection
    st.subheader("Model Settings")
    st.session_state.selected_chat_model = st.selectbox(
        "Chat Model:",
        CHAT_MODELS,
        index=CHAT_MODELS.index(st.session_state.selected_chat_model)
    )
    
    st.session_state.selected_embedding_model = st.selectbox(
        "Embedding Model:",
        EMBEDDING_MODELS,
        index=EMBEDDING_MODELS.index(st.session_state.selected_embedding_model)
    )
    
    # Character Selection
    st.subheader("Character Persona")
    current_session = get_current_session()
    selected_character = st.selectbox(
        "Select Character:",
        list(CHARACTER_PERSONAS.keys()),
        index=list(CHARACTER_PERSONAS.keys()).index(current_session.get("character", "Default Assistant"))
    )
    
    if current_session["character"] != selected_character:
        current_session["character"] = selected_character
        # Update system message with new character
        current_session["messages"][0] = SystemMessage(content=CHARACTER_PERSONAS[selected_character])
    
    st.divider()
    
    # Multi-Document Upload Section
    st.subheader("Document Upload")
    uploaded_files = st.file_uploader(
        "Upload Documents for Analysis (PDF/DOCX/TXT)", 
        type=["pdf", "docx", "txt"],
        accept_multiple_files=True,
        key="multifile"
    )
    
    if uploaded_files:
        if st.button("Process Documents"):
            create_new_session("document")
            current_session = get_current_session()
            current_session["pdf_name"] = ", ".join([f.name for f in uploaded_files])
            
            with st.spinner("Processing documents..."):
                try:
                    all_texts = []
                    all_entities = {}
                    
                    for file in uploaded_files:
                        file_type = file.name.split('.')[-1].lower()
                        text = extract_text_from_file(file, file_type)
                        all_texts.append(text)
                        
                        # NER per document
                        entities = extract_entities(text)
                        all_entities[file.name] = entities
                    
                    # Combine all texts for cross-analysis
                    combined_text = "\n\n".join(all_texts)
                    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
                    chunks = text_splitter.split_text(combined_text)
                    
                    # Embedding model
                    embedding_model = OpenAIEmbeddings(
                        base_url=BASE_URL,
                        model=st.session_state.selected_embedding_model,
                        api_key=API_KEY,
                        http_client=client
                    )
                    
                    vectordb = Chroma.from_texts(chunks, embedding_model, persist_directory="./chroma_index")
                    vectordb.persist()
                    
                    # LLM model
                    llm = ChatOpenAI(
                        base_url=BASE_URL,
                        model=st.session_state.selected_chat_model,
                        api_key=API_KEY,
                        http_client=client
                    )
                    
                    retriever = vectordb.as_retriever()
                    rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)
                    
                    current_session["rag_chain"] = rag_chain
                    current_session["rag_ready"] = True
                    current_session["text_chunks"] = chunks
                    current_session["all_doc_entities"] = all_entities
                    
                    st.success("All documents processed and cross-indexed successfully!")
                    st.rerun()
                except Exception as e:
                    st.error(f"Error processing documents: {str(e)}")
    
    # Document Actions (only show if document is loaded)
    current_session = get_current_session()
    if current_session["rag_ready"]:
        st.subheader("Document Actions")
        
        # Download format selection
        download_format = st.selectbox(
            "Download Format:",
            ["txt", "pdf", "pptx"],
            key="download_format"
        )
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("Generate Summary"):
                with st.spinner("Generating summary..."):
                    summary = generate_pdf_summary(current_session["text_chunks"])
                    filename = current_session["pdf_name"].replace(", ", "_").replace(".pdf", "").replace(".docx", "").replace(".txt", "")
                    
                    if download_format == "txt":
                        st.download_button(
                            label="Download TXT",
                            data=summary,
                            file_name=f"{filename}_summary.txt",
                            mime="text/plain"
                        )
                    elif download_format == "pdf":
                        pdf_data = create_pdf(summary, filename)
                        st.download_button(
                            label="Download PDF",
                            data=pdf_data,
                            file_name=f"{filename}_summary.pdf",
                            mime="application/pdf"
                        )
                    elif download_format == "pptx":
                        pptx_data = create_pptx(summary, filename)
                        st.download_button(
                            label="Download PPTX",
                            data=pptx_data,
                            file_name=f"{filename}_summary.pptx",
                            mime="application/vnd.openxmlformats-officedocument.presentationml.presentation"
                        )
        
        with col2:
            if st.button("Show NER"):
                st.session_state.show_ner = not st.session_state.show_ner
                st.rerun()
    
    st.divider()
    
    # Session Management
    st.subheader("Chat Sessions")
    
    # New Chat Button
    if st.button("New Chat"):
        create_new_session("chat")
        st.rerun()
    
    # Display sessions
    for session_id in list(st.session_state.chat_sessions.keys()):
        session = st.session_state.chat_sessions[session_id]
        session_type = "Document" if session["session_type"] == "document" else "Chat"
        session_name = f"{session_type} - {session_id}"
        
        if session.get("pdf_name"):
            session_name = f"{session['pdf_name'][:15]}... - {session_id[-8:]}"
        
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            if st.button(
                session_name,
                key=f"session_{session_id}",
                type="primary" if session_id == st.session_state.current_session_id else "secondary"
            ):
                st.session_state.current_session_id = session_id
                st.rerun()
        
        with col2:
            # Chat history download button
            if len(session["messages"]) > 1:  # More than just system message
                chat_pdf = create_chat_history_pdf(session["messages"], session_id[-8:])
                st.download_button(
                    label="D",
                    data=chat_pdf,
                    file_name=f"chat_history_{session_id[-8:]}.pdf",
                    mime="application/pdf",
                    key=f"download_chat_{session_id}",
                    help="Download chat history"
                )
        
        with col3:
            if st.button("X", key=f"delete_{session_id}", help="Delete session"):
                delete_session(session_id)
                st.rerun()
    
    # Clear All Chats
    if st.button("Clear All Chats"):
        st.session_state.chat_sessions = {}
        create_new_session("chat")
        st.rerun()

# Main Chat Interface
current_session = get_current_session()
session_type_icon = "Document" if current_session["session_type"] == "document" else "Chat"

if current_session.get("pdf_name"):
    st.title(f"{session_type_icon} Chat - {current_session['pdf_name']}")
else:
    st.title(f"{session_type_icon} AI Chat Assistant")

# Display current model info and character
st.caption(f"Using: {st.session_state.selected_chat_model} | Character: {current_session['character']} | Session: {st.session_state.current_session_id[-8:]}")

# Display NER results in main page if requested (Multi-document support)
if st.session_state.show_ner and current_session.get("all_doc_entities"):
    with st.container():
        st.markdown("### Named Entities Analysis per Document")
        for docname, entities in current_session["all_doc_entities"].items():
            st.markdown(f"**{docname}**")
            entity_display = format_entities_for_display(entities)
            st.markdown(entity_display)
        st.divider()
elif st.session_state.show_ner and current_session.get("entities"):
    with st.container():
        st.markdown("### Named Entities Analysis")
        entity_display = format_entities_for_display(current_session["entities"])
        st.markdown(entity_display)
        st.divider()

# Display chat messages
display_chat(current_session["messages"])

# Chat input
if current_session["rag_ready"]:
    prompt = st.chat_input("Ask a question about the uploaded document(s)...")
    if prompt:
        # Add character persona to the prompt
        character_context = CHARACTER_PERSONAS[current_session["character"]]
        enhanced_prompt = f"{character_context}\n\nUser question: {prompt}"
        
        # Add user message
        current_session["messages"].append(HumanMessage(content=prompt))
        st.chat_message("user").write(prompt)
        
        # Generate response
        with st.spinner("Thinking..."):
            result = current_session["rag_chain"].invoke(enhanced_prompt)
            answer = result["result"]
            current_session["messages"].append(AIMessage(content=answer))
            st.chat_message("assistant").write(answer)
            st.rerun()

else:
    prompt = st.chat_input("Ask me anything...")
    if prompt:
        # Add user message
        current_session["messages"].append(HumanMessage(content=prompt))
        st.chat_message("user").write(prompt)
        
        # Generate response
        with st.spinner("Thinking..."):
            chat = ChatOpenAI(
                base_url=BASE_URL,
                api_key=API_KEY,
                temperature=0.7,
                model=st.session_state.selected_chat_model,
                http_client=client
            )

            class AgentState(TypedDict):
                messages: List[Union[HumanMessage, AIMessage, SystemMessage]]

            def first_node(state: AgentState) -> AgentState:
                # Add character context to the conversation
                character_context = CHARACTER_PERSONAS[current_session["character"]]
                enhanced_messages = state["messages"].copy()
                enhanced_messages[0] = SystemMessage(content=character_context)
                
                response = chat.invoke(enhanced_messages)
                state["messages"].append(AIMessage(content=response.content))
                return state

            graph = StateGraph(AgentState)
            graph.add_node("node1", first_node)
            graph.add_edge(START, "node1")
            graph.add_edge("node1", END)
            agent = graph.compile()

            state_input = {"messages": current_session["messages"].copy()}
            result = agent.invoke(state_input)
            response = result["messages"][-1].content

            current_session["messages"].append(AIMessage(content=response))
            st.chat_message("assistant").write(response)
            st.rerun()
