from typing import TypedDict, List, Union
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, START, END
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains.retrieval_qa.base import RetrievalQA
from pdfplumber.high_level import extract_text
import tempfile
import os
import httpx
import tiktoken
import streamlit as st
from datetime import datetime
import json
from io import BytesIO
from pptx import Presentation
from pptx.util import Pt
from fpdf import FPDF
import spacy
import docx
from reportlab.lib.pagesizes import letter
from reportlab.lib.styles import getSampleStyleSheet
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
import uuid
import shutil

# Configuration Variables
API_KEY = "your-api-key-here"
BASE_URL = "https://your-base-url-here"

# Available Models List
CHAT_MODELS = [
    "gpt-4o",
    "gpt-4o-mini", 
    "gpt-4-turbo",
    "gpt-4",
    "gpt-3.5-turbo",
    "text-davinci-003",
    "your-custom-model-1",
    "your-custom-model-2"
]

EMBEDDING_MODELS = [
    "text-embedding-ada-002",
    "text-embedding-3-small",
    "text-embedding-3-large",
    "your-custom-embedding-model"
]

# Character Personas
CHARACTER_PERSONAS = {
    "Default Assistant": "You are a helpful and knowledgeable assistant.",
    "Friendly Teacher": "You are a friendly and patient teacher who explains things clearly and encourages learning.",
    "Professional Consultant": "You are a professional business consultant who provides strategic advice and analysis.",
    "Creative Writer": "You are a creative writer who helps with storytelling, creative content, and imaginative ideas.",
    "Technical Expert": "You are a technical expert who provides detailed technical explanations and solutions.",
    "Casual Friend": "You are a casual and friendly companion who chats in a relaxed, conversational manner.",
    "Academic Researcher": "You are an academic researcher who provides scholarly insights and detailed analysis.",
    "Motivational Coach": "You are an enthusiastic motivational coach who inspires and encourages positive action."
}

# Configure
st.set_page_config(page_title='RAG PDF Summarizer Chatbot', layout='wide')

tiktoken_cache_dir = "./token"
os.environ["TIKTOKEN_CACHE_DIR"] = tiktoken_cache_dir

# Create httpx client with proper settings
@st.cache_resource
def get_http_client():
    return httpx.Client(verify=False, timeout=30.0)

client = get_http_client()

# Load NER model
@st.cache_resource
def load_ner_model():
    try:
        return spacy.load("en_core_web_sm")
    except IOError:
        st.warning("spaCy English model not found. Install with: python -m spacy download en_core_web_sm")
        return None

nlp = load_ner_model()

# Document processing functions
def extract_text_from_file(file, file_type):
    """Extract text from various file types"""
    try:
        if file_type == "pdf":
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                tmp.write(file.getvalue())
                temp_path = tmp.name
            text = extract_text(temp_path)
            os.unlink(temp_path)
            return text
        
        elif file_type == "docx":
            doc = docx.Document(BytesIO(file.getvalue()))
            text = []
            for paragraph in doc.paragraphs:
                if paragraph.text.strip():
                    text.append(paragraph.text)
            return '\n'.join(text)
        
        elif file_type == "txt":
            return file.getvalue().decode('utf-8')
        
        else:
            raise ValueError(f"Unsupported file type: {file_type}")
    
    except Exception as e:
        st.error(f"Error extracting text: {str(e)}")
        return None

# File generation functions
def create_pptx(summary_text: str, filename: str) -> bytes:
    """Create PowerPoint file from text"""
    try:
        prs = Presentation()
        
        # Title slide
        title_slide_layout = prs.slide_layouts[0]
        slide = prs.slides.add_slide(title_slide_layout)
        title = slide.shapes.title
        subtitle = slide.placeholders[1]
        title.text = f"Summary: {filename}"
        subtitle.text = "Generated Summary"
        
        # Content slide
        bullet_slide_layout = prs.slide_layouts[1]
        slide = prs.slides.add_slide(bullet_slide_layout)
        shapes = slide.shapes
        title_shape = shapes.title
        body_shape = shapes.placeholders[1]
        
        title_shape.text = "Key Points"
        tf = body_shape.text_frame
        tf.clear()
        
        # Add bullet points
        lines = [line.strip() for line in summary_text.split('\n') if line.strip()]
        for i, line in enumerate(lines[:10]):  # Limit to 10 points
            if i == 0:
                tf.text = line
            else:
                p = tf.add_paragraph()
                p.text = line
                p.level = 0
                p.font.size = Pt(14)
        
        # Save to bytes
        pptx_io = BytesIO()
        prs.save(pptx_io)
        pptx_io.seek(0)
        return pptx_io.read()
    except Exception as e:
        st.error(f"Error creating PowerPoint: {str(e)}")
        return None

def create_pdf_summary(text: str, filename: str) -> bytes:
    """Create PDF file from text"""
    try:
        pdf = FPDF()
        pdf.add_page()
        pdf.set_auto_page_break(auto=True, margin=15)
        
        # Title
        pdf.set_font("Arial", 'B', 16)
        pdf.cell(0, 10, f'Summary: {filename}', ln=True, align='C')
        pdf.ln(10)
        
        # Content
        pdf.set_font("Arial", size=12)
        for line in text.split('\n'):
            if line.strip():
                try:
                    pdf.multi_cell(0, 8, line.strip())
                    pdf.ln(2)
                except:
                    # Handle special characters
                    clean_line = line.encode('latin1', 'replace').decode('latin1')
                    pdf.multi_cell(0, 8, clean_line)
                    pdf.ln(2)
        
        pdf_output = BytesIO()
        pdf.output(pdf_output)
        pdf_output.seek(0)
        return pdf_output.read()
    except Exception as e:
        st.error(f"Error creating PDF: {str(e)}")
        return None

def create_chat_history_pdf(messages: List[Union[HumanMessage, AIMessage, SystemMessage]], session_id: str) -> bytes:
    """Create PDF from chat history"""
    try:
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=letter)
        story = []
        styles = getSampleStyleSheet()
        
        # Title
        title = Paragraph(f"Chat History - {session_id}", styles['Title'])
        story.append(title)
        story.append(Spacer(1, 12))
        
        # Chat messages
        for msg in messages[1:]:  # Skip system message
            if isinstance(msg, HumanMessage):
                user_text = f"<b>Human:</b> {msg.content}"
                story.append(Paragraph(user_text, styles['Normal']))
                story.append(Spacer(1, 6))
            elif isinstance(msg, AIMessage):
                ai_text = f"<b>Assistant:</b> {msg.content}"
                story.append(Paragraph(ai_text, styles['Normal']))
                story.append(Spacer(1, 12))
        
        doc.build(story)
        buffer.seek(0)
        return buffer.read()
    except Exception as e:
        st.error(f"Error creating chat PDF: {str(e)}")
        return None

def extract_entities(text: str) -> dict:
    """Extract named entities using spaCy NER"""
    if not nlp:
        return {}
    
    try:
        # Limit text size to prevent memory issues
        text_sample = text[:50000]  
        doc = nlp(text_sample)
        entities = {}
        
        for ent in doc.ents:
            if ent.label_ not in entities:
                entities[ent.label_] = []
            if ent.text not in entities[ent.label_] and len(entities[ent.label_]) < 10:
                entities[ent.label_].append(ent.text)
        
        return entities
    except Exception as e:
        st.error(f"Error extracting entities: {str(e)}")
        return {}

def format_entities_for_display(entities: dict) -> str:
    """Format entities for nice display"""
    if not entities:
        return "No entities found."
    
    formatted = "## Named Entities Found:\n\n"
    
    entity_labels = {
        'PERSON': 'People',
        'ORG': 'Organizations', 
        'GPE': 'Places',
        'MONEY': 'Money',
        'DATE': 'Dates',
        'TIME': 'Times',
        'PRODUCT': 'Products',
        'EVENT': 'Events',
        'WORK_OF_ART': 'Works of Art',
        'LAW': 'Laws',
        'LANGUAGE': 'Languages'
    }
    
    for label, items in entities.items():
        display_label = entity_labels.get(label, label)
        formatted += f"**{display_label}:**\n"
        for item in items[:5]:  # Limit to 5 per category
            formatted += f"- {item}\n"
        formatted += "\n"
    
    return formatted

# Initialize session state
def initialize_session_state():
    """Initialize all session state variables"""
    # Core session management
    if "chat_sessions" not in st.session_state:
        st.session_state.chat_sessions = {}
    
    if "current_session_id" not in st.session_state:
        session_id = str(uuid.uuid4())
        st.session_state.current_session_id = session_id
        st.session_state.chat_sessions[session_id] = create_default_session()
    
    # Model settings
    if "selected_chat_model" not in st.session_state:
        st.session_state.selected_chat_model = CHAT_MODELS[0]
    
    if "selected_embedding_model" not in st.session_state:
        st.session_state.selected_embedding_model = EMBEDDING_MODELS[0]
    
    # UI state
    if "show_ner" not in st.session_state:
        st.session_state.show_ner = False
    
    if "document_processed" not in st.session_state:
        st.session_state.document_processed = False

def create_default_session():
    """Create a default session structure"""
    return {
        "messages": [SystemMessage(content=CHARACTER_PERSONAS["Default Assistant"])],
        "rag_chain": None,
        "rag_ready": False,
        "document_name": None,
        "session_type": "chat",
        "text_chunks": None,
        "entities": None,
        "character": "Default Assistant",
        "vectordb_path": None
    }

def get_current_session():
    """Get the current active session"""
    return st.session_state.chat_sessions[st.session_state.current_session_id]

def create_new_session(session_type="chat"):
    """Create a new session"""
    session_id = str(uuid.uuid4())
    st.session_state.chat_sessions[session_id] = create_default_session()
    st.session_state.chat_sessions[session_id]["session_type"] = session_type
    st.session_state.current_session_id = session_id
    st.session_state.show_ner = False
    return session_id

def delete_session(session_id):
    """Delete a session"""
    if len(st.session_state.chat_sessions) > 1:
        # Clean up vectordb if exists
        session = st.session_state.chat_sessions.get(session_id, {})
        if session.get("vectordb_path") and os.path.exists(session["vectordb_path"]):
            try:
                shutil.rmtree(session["vectordb_path"])
            except:
                pass
        
        del st.session_state.chat_sessions[session_id]
        if st.session_state.current_session_id == session_id:
            st.session_state.current_session_id = list(st.session_state.chat_sessions.keys())[0]

# Helper to display chat messages
def display_chat(messages: List[Union[HumanMessage, AIMessage, SystemMessage]]):
    """Display chat messages in the interface"""
    for msg in messages[1:]:  # Skip system message
        if isinstance(msg, HumanMessage):
            with st.chat_message("user"):
                st.write(msg.content)
        elif isinstance(msg, AIMessage):
            with st.chat_message("assistant"):
                st.write(msg.content)

# Generate document summary
def generate_document_summary(text_chunks, character_persona):
    """Generate summary of document chunks"""
    try:
        chat = ChatOpenAI(
            base_url=BASE_URL,
            api_key=API_KEY,
            model=st.session_state.selected_chat_model,
            http_client=client
        )
        
        combined_text = "\n".join(text_chunks[:10])  # Limit for summary
        summary_prompt = f"""
        {character_persona}
        
        Please provide a comprehensive summary of the following document content:
        
        {combined_text}
        """
        
        response = chat.invoke([HumanMessage(content=summary_prompt)])
        return response.content
    except Exception as e:
        st.error(f"Error generating summary: {str(e)}")
        return None

# Process document function
def process_document(uploaded_file):
    """Process uploaded document and create RAG chain"""
    try:
        # Extract text
        file_type = uploaded_file.name.split('.')[-1].lower()
        raw_text = extract_text_from_file(uploaded_file, file_type)
        
        if not raw_text or len(raw_text.strip()) < 10:
            st.error("Could not extract sufficient text from document")
            return False
        
        # Get current session
        current_session = get_current_session()
        
        # Split text into chunks
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000, 
            chunk_overlap=200,
            separators=["\n\n", "\n", " ", ""]
        )
        chunks = text_splitter.split_text(raw_text)
        
        if not chunks:
            st.error("Could not create text chunks from document")
            return False
        
        # Extract entities
        entities = extract_entities(raw_text)
        
        # Create unique vectordb path for this session
        vectordb_path = f"./chroma_index_{st.session_state.current_session_id}"
        
        # Create embeddings
        embedding_model = OpenAIEmbeddings(
            base_url=BASE_URL,
            model=st.session_state.selected_embedding_model,
            api_key=API_KEY,
            http_client=client
        )
        
        # Create vector store
        vectordb = Chroma.from_texts(
            chunks, 
            embedding_model, 
            persist_directory=vectordb_path
        )
        vectordb.persist()
        
        # Create LLM
        llm = ChatOpenAI(
            base_url=BASE_URL,
            model=st.session_state.selected_chat_model,
            api_key=API_KEY,
            http_client=client
        )
        
        # Create RAG chain
        retriever = vectordb.as_retriever(search_kwargs={"k": 3})
        rag_chain = RetrievalQA.from_chain_type(
            llm=llm, 
            retriever=retriever, 
            return_source_documents=True
        )
        
        # Update session
        current_session.update({
            "rag_chain": rag_chain,
            "rag_ready": True,
            "document_name": uploaded_file.name,
            "text_chunks": chunks,
            "entities": entities,
            "vectordb_path": vectordb_path,
            "session_type": "document"
        })
        
        return True
        
    except Exception as e:
        st.error(f"Error processing document: {str(e)}")
        return False

# Initialize
initialize_session_state()

# Main UI
st.title("ðŸ¤– AI RAG Chat Assistant")

# Sidebar
with st.sidebar:
    st.header("âš™ï¸ Settings")
    
    # Model Selection
    st.subheader("Models")
    st.session_state.selected_chat_model = st.selectbox(
        "Chat Model:",
        CHAT_MODELS,
        index=CHAT_MODELS.index(st.session_state.selected_chat_model),
        key="chat_model_select"
    )
    
    st.session_state.selected_embedding_model = st.selectbox(
        "Embedding Model:",
        EMBEDDING_MODELS,
        index=EMBEDDING_MODELS.index(st.session_state.selected_embedding_model),
        key="embedding_model_select"
    )
    
    # Character Selection
    st.subheader("Character")
    current_session = get_current_session()
    selected_character = st.selectbox(
        "Select Character:",
        list(CHARACTER_PERSONAS.keys()),
        index=list(CHARACTER_PERSONAS.keys()).index(current_session.get("character", "Default Assistant")),
        key="character_select"
    )
    
    # Update character if changed
    if current_session["character"] != selected_character:
        current_session["character"] = selected_character
        current_session["messages"][0] = SystemMessage(content=CHARACTER_PERSONAS[selected_character])
    
    st.divider()
    
    # Document Upload
    st.subheader("ðŸ“„ Document Upload")
    uploaded_file = st.file_uploader(
        "Upload Document", 
        type=["pdf", "docx", "txt"],
        key="file_uploader"
    )
    
    if uploaded_file:
        if st.button("ðŸš€ Process Document", key="process_btn"):
            with st.spinner("Processing document..."):
                # Create new document session
                create_new_session("document")
                
                if process_document(uploaded_file):
                    st.success("âœ… Document processed successfully!")
                    st.session_state.document_processed = True
                else:
                    st.error("âŒ Failed to process document")
    
    # Document Actions
    current_session = get_current_session()
    if current_session.get("rag_ready", False):
        st.subheader("ðŸ“Š Document Tools")
        
        # Download format
        download_format = st.selectbox(
            "Format:",
            ["txt", "pdf", "pptx"],
            key="download_format_select"
        )
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("ðŸ“‹ Summary", key="summary_btn"):
                with st.spinner("Generating..."):
                    character_persona = CHARACTER_PERSONAS[current_session["character"]]
                    summary = generate_document_summary(current_session["text_chunks"], character_persona)
                    
                    if summary:
                        filename = current_session["document_name"].rsplit('.', 1)[0]
                        
                        if download_format == "txt":
                            st.download_button(
                                "ðŸ’¾ Download TXT",
                                data=summary,
                                file_name=f"{filename}_summary.txt",
                                mime="text/plain",
                                key="download_txt"
                            )
                        elif download_format == "pdf":
                            pdf_data = create_pdf_summary(summary, filename)
                            if pdf_data:
                                st.download_button(
                                    "ðŸ’¾ Download PDF",
                                    data=pdf_data,
                                    file_name=f"{filename}_summary.pdf",
                                    mime="application/pdf",
                                    key="download_pdf"
                                )
                        elif download_format == "pptx":
                            pptx_data = create_pptx(summary, filename)
                            if pptx_data:
                                st.download_button(
                                    "ðŸ’¾ Download PPTX",
                                    data=pptx_data,
                                    file_name=f"{filename}_summary.pptx",
                                    mime="application/vnd.openxmlformats-officedocument.presentationml.presentation",
                                    key="download_pptx"
                                )
        
        with col2:
            if st.button("ðŸ” NER", key="ner_btn"):
                st.session_state.show_ner = not st.session_state.show_ner
    
    st.divider()
    
    # Session Management
    st.subheader("ðŸ’¬ Sessions")
    
    if st.button("âž• New Chat", key="new_chat_btn"):
        create_new_session("chat")
    
    # Display sessions
    for idx, session_id in enumerate(list(st.session_state.chat_sessions.keys())):
        session = st.session_state.chat_sessions[session_id]
        
        # Session display name
        if session.get("document_name"):
            display_name = f"ðŸ“„ {session['document_name'][:20]}..."
        else:
            display_name = f"ðŸ’¬ Chat {idx + 1}"
        
        col1, col2, col3 = st.columns([3, 1, 1])
        
        with col1:
            if st.button(
                display_name,
                key=f"session_btn_{session_id}",
                type="primary" if session_id == st.session_state.current_session_id else "secondary"
            ):
                st.session_state.current_session_id = session_id
                st.session_state.show_ner = False
        
        with col2:
            # Download chat history
            if len(session["messages"]) > 1:
                chat_pdf = create_chat_history_pdf(session["messages"], f"session_{idx+1}")
                if chat_pdf:
                    st.download_button(
                        "ðŸ“¥",
                        data=chat_pdf,
                        file_name=f"chat_history_{idx+1}.pdf",
                        mime="application/pdf",
                        key=f"download_chat_{session_id}",
                        help="Download chat history"
                    )
        
        with col3:
            if st.button("ðŸ—‘ï¸", key=f"delete_btn_{session_id}", help="Delete session"):
                delete_session(session_id)
    
    if st.button("ðŸ§¹ Clear All", key="clear_all_btn"):
        # Clean up all vectordbs
        for session in st.session_state.chat_sessions.values():
            if session.get("vectordb_path") and os.path.exists(session["vectordb_path"]):
                try:
                    shutil.rmtree(session["vectordb_path"])
                except:
                    pass
        
        st.session_state.chat_sessions = {}
        create_new_session("chat")
        st.session_state.show_ner = False

# Main content area
current_session = get_current_session()

# Display session info
if current_session.get("document_name"):
    st.info(f"ðŸ“„ Document Session: **{current_session['document_name']}** | Character: **{current_session['character']}**")
else:
    st.info(f"ðŸ’¬ Chat Session | Character: **{current_session['character']}**")

# Display NER results if requested
if st.session_state.show_ner and current_session.get("entities"):
    with st.expander("ðŸ” Named Entity Recognition Results", expanded=True):
        entity_display = format_entities_for_display(current_session["entities"])
        st.markdown(entity_display)

# Display chat history
if current_session["messages"]:
    display_chat(current_session["messages"])

# Chat input
if current_session.get("rag_ready", False):
    # Document chat mode
    if prompt := st.chat_input("Ask about the document..."):
        # Add user message
        current_session["messages"].append(HumanMessage(content=prompt))
        with st.chat_message("user"):
            st.write(prompt)
        
        # Generate response
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                try:
                    # Enhance prompt with character context
                    character_context = CHARACTER_PERSONAS[current_session["character"]]
                    enhanced_prompt = f"{character_context}\n\nUser question about the document: {prompt}"
                    
                    result = current_session["rag_chain"].invoke({"query": enhanced_prompt})
                    answer = result["result"]
                    
                    current_session["messages"].append(AIMessage(content=answer))
                    st.write(answer)
                    
                except Exception as e:
                    error_msg = f"Error: {str(e)}"
                    current_session["messages"].append(AIMessage(content=error_msg))
                    st.error(error_msg)
else:
    # Regular chat mode
    if prompt := st.chat_input("Ask me anything..."):
        # Add user message
        current_session["messages"].append(HumanMessage(content=prompt))
        with st.chat_message("user"):
            st.write(prompt)
        
        # Generate response
        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                try:
                    chat = ChatOpenAI(
                        base_url=BASE_URL,
                        api_key=API_KEY,
                        temperature=0.7,
                        model=st.session_state.selected_chat_model,
                        http_client=client
                    )

                    class AgentState(TypedDict):
                        messages: List[Union[HumanMessage, AIMessage, SystemMessage]]

                    def chat_node(state: AgentState) -> AgentState:
                        # Use character persona
                        character_context = CHARACTER_PERSONAS[current_session["character"]]
                        enhanced_messages = state["messages"].copy()
                        enhanced_messages[0] = SystemMessage(content=character_context)
                        
                        response = chat.invoke(enhanced_messages)
                        state["messages"].append(AIMessage(content=response.content))
                        return state

                    graph = StateGraph(AgentState)
                    graph.add_node("chat", chat_node)
                    graph.add_edge(START, "chat")
                    graph.add_edge("chat", END)
                    agent = graph.compile()

                    state_input = {"messages": current_session["messages"].copy()}
                    result = agent.invoke(state_input)
                    response = result["messages"][-1].content

                    current_session["messages"].append(AIMessage(content=response))
                    st.write(response)
                    
                except Exception as e:
                    error_msg = f"Error: {str(e)}"
                    current_session["messages"].append(AIMessage(content=error_msg))
                    st.error(error_msg)
