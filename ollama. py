from typing import TypedDict, List, Union
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, START, END
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains.retrieval_qa.base import RetrievalQA
from pdfplumber.high_level import extract_text
import tempfile
import os
import httpx
import tiktoken
import streamlit as st
from datetime import datetime
import json
from io import BytesIO
from pptx import Presentation
from pptx.util import Pt
from fpdf import FPDF
import spacy

# Configuration Variables
API_KEY = "your-api-key-here"
BASE_URL = "https://your-base-url-here"

# Available Models List
CHAT_MODELS = [
    "gpt-4o",
    "gpt-4o-mini", 
    "gpt-4-turbo",
    "gpt-4",
    "gpt-3.5-turbo",
    "text-davinci-003",
    "your-custom-model-1",
    "your-custom-model-2"
]

EMBEDDING_MODELS = [
    "text-embedding-ada-002",
    "text-embedding-3-small",
    "text-embedding-3-large",
    "your-custom-embedding-model"
]

# Configure
st.set_page_config(page_title='RAG PDF Summarizer Chatbot', layout='wide')

tiktoken_cache_dir = "./token"
os.environ["TIKTOKEN_CACHE_DIR"] = tiktoken_cache_dir
client = httpx.Client(verify=False)

# Load NER model
@st.cache_resource
def load_ner_model():
    try:
        return spacy.load("en_core_web_sm")
    except IOError:
        st.error("Please install spaCy English model: python -m spacy download en_core_web_sm")
        return None

nlp = load_ner_model()

# File generation functions
def create_pptx(summary_text: str, filename: str) -> bytes:
    """Create PowerPoint file from text"""
    prs = Presentation()
    
    # Title slide
    title_slide_layout = prs.slide_layouts[0]
    slide = prs.slides.add_slide(title_slide_layout)
    title = slide.shapes.title
    subtitle = slide.placeholders[1]
    title.text = f"Summary: {filename}"
    subtitle.text = "Generated Summary"
    
    # Content slide
    bullet_slide_layout = prs.slide_layouts[1]
    slide = prs.slides.add_slide(bullet_slide_layout)
    shapes = slide.shapes
    title_shape = shapes.title
    body_shape = shapes.placeholders[1]
    
    title_shape.text = "Key Points"
    tf = body_shape.text_frame
    tf.clear()
    
    # Add bullet points
    lines = [line.strip() for line in summary_text.split('\n') if line.strip()]
    for i, line in enumerate(lines[:10]):  # Limit to 10 points
        if i == 0:
            tf.text = line
        else:
            p = tf.add_paragraph()
            p.text = line
            p.level = 0
            p.font.size = Pt(14)
    
    # Save to bytes
    pptx_io = BytesIO()
    prs.save(pptx_io)
    pptx_io.seek(0)
    return pptx_io.read()

def create_pdf(text: str, filename: str) -> bytes:
    """Create PDF file from text"""
    pdf = FPDF()
    pdf.add_page()
    pdf.set_auto_page_break(auto=True, margin=15)
    
    # Title
    pdf.set_font("Arial", 'B', 16)
    pdf.cell(0, 10, f'Summary: {filename}', ln=True, align='C')
    pdf.ln(10)
    
    # Content
    pdf.set_font("Arial", size=12)
    for line in text.split('\n'):
        if line.strip():
            pdf.multi_cell(0, 8, line.strip())
            pdf.ln(2)
    
    pdf_output = BytesIO()
    pdf.output(pdf_output)
    pdf_output.seek(0)
    return pdf_output.read()

def extract_entities(text: str) -> dict:
    """Extract named entities using spaCy NER"""
    if not nlp:
        return {}
    
    doc = nlp(text)
    entities = {}
    
    for ent in doc.ents:
        if ent.label_ not in entities:
            entities[ent.label_] = []
        if ent.text not in entities[ent.label_]:
            entities[ent.label_].append(ent.text)
    
    return entities

def format_entities_for_display(entities: dict) -> str:
    """Format entities for nice display"""
    if not entities:
        return "No entities found."
    
    formatted = "## Named Entities Found:\n\n"
    
    entity_labels = {
        'PERSON': 'üë§ People',
        'ORG': 'üè¢ Organizations', 
        'GPE': 'üåç Places',
        'MONEY': 'üí∞ Money',
        'DATE': 'üìÖ Dates',
        'TIME': '‚è∞ Times',
        'PRODUCT': 'üì¶ Products',
        'EVENT': 'üéâ Events',
        'WORK_OF_ART': 'üé® Works of Art',
        'LAW': '‚öñÔ∏è Laws',
        'LANGUAGE': 'üó£Ô∏è Languages'
    }
    
    for label, items in entities.items():
        display_label = entity_labels.get(label, f'üìã {label}')
        formatted += f"**{display_label}:**\n"
        for item in items[:5]:  # Limit to 5 per category
            formatted += f"- {item}\n"
        formatted += "\n"
    
    return formatted

# Initialize session state
def initialize_session_state():
    if "chat_sessions" not in st.session_state:
        st.session_state.chat_sessions = {}
    
    if "current_session_id" not in st.session_state:
        session_id = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        st.session_state.current_session_id = session_id
        st.session_state.chat_sessions[session_id] = {
            "messages": [SystemMessage(content="You are a helpful assistant.")],
            "rag_chain": None,
            "rag_ready": False,
            "pdf_name": None,
            "session_type": "chat",
            "text_chunks": None,
            "entities": None
        }
    
    if "selected_chat_model" not in st.session_state:
        st.session_state.selected_chat_model = CHAT_MODELS[0]
    
    if "selected_embedding_model" not in st.session_state:
        st.session_state.selected_embedding_model = EMBEDDING_MODELS[0]

def get_current_session():
    return st.session_state.chat_sessions[st.session_state.current_session_id]

def create_new_session(session_type="chat"):
    session_id = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.session_state.chat_sessions[session_id] = {
        "messages": [SystemMessage(content="You are a helpful assistant.")],
        "rag_chain": None,
        "rag_ready": False,
        "pdf_name": None,
        "session_type": session_type,
        "text_chunks": None,
        "entities": None
    }
    st.session_state.current_session_id = session_id
    return session_id

def delete_session(session_id):
    if len(st.session_state.chat_sessions) > 1:
        del st.session_state.chat_sessions[session_id]
        if st.session_state.current_session_id == session_id:
            st.session_state.current_session_id = list(st.session_state.chat_sessions.keys())[0]

# Helper to display chat messages
def display_chat(messages: List[Union[HumanMessage, AIMessage, SystemMessage]]):
    for msg in messages[1:]:  # Skip system message
        if isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)

# Generate PDF Summary
def generate_pdf_summary(text_chunks):
    chat = ChatOpenAI(
        base_url=BASE_URL,
        api_key=API_KEY,
        model=st.session_state.selected_chat_model,
        http_client=client
    )
    
    combined_text = "\n".join(text_chunks[:10])  # Limit for summary
    summary_prompt = f"Please provide a comprehensive summary of the following PDF content:\n\n{combined_text}"
    
    response = chat.invoke([HumanMessage(content=summary_prompt)])
    return response.content

# Initialize
initialize_session_state()

# Sidebar
with st.sidebar:
    st.title("ü§ñ AI Chat Assistant")
    
    # Model Selection
    st.subheader("üõ†Ô∏è Model Settings")
    st.session_state.selected_chat_model = st.selectbox(
        "Chat Model:",
        CHAT_MODELS,
        index=CHAT_MODELS.index(st.session_state.selected_chat_model)
    )
    
    st.session_state.selected_embedding_model = st.selectbox(
        "Embedding Model:",
        EMBEDDING_MODELS,
        index=EMBEDDING_MODELS.index(st.session_state.selected_embedding_model)
    )
    
    st.divider()
    
    # PDF Upload Section
    st.subheader("üìÑ PDF Upload")
    uploaded_file = st.file_uploader("Upload PDF for Analysis", type="pdf")
    
    if uploaded_file:
        if st.button("üöÄ Process PDF"):
            # Create new PDF session
            create_new_session("pdf")
            current_session = get_current_session()
            current_session["pdf_name"] = uploaded_file.name
            
            with st.spinner("Processing PDF..."):
                with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                    tmp.write(uploaded_file.read())
                    temp_pdf_path = tmp.name
                
                raw_text = extract_text(temp_pdf_path)
                text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
                chunks = text_splitter.split_text(raw_text)
                
                # Extract entities
                entities = extract_entities(raw_text)
                current_session["entities"] = entities
                
                # Embedding model
                embedding_model = OpenAIEmbeddings(
                    base_url=BASE_URL,
                    model=st.session_state.selected_embedding_model,
                    api_key=API_KEY,
                    http_client=client
                )
                
                vectordb = Chroma.from_texts(chunks, embedding_model, persist_directory="./chroma_index")
                vectordb.persist()
                
                # LLM model
                llm = ChatOpenAI(
                    base_url=BASE_URL,
                    model=st.session_state.selected_chat_model,
                    api_key=API_KEY,
                    http_client=client
                )
                
                retriever = vectordb.as_retriever()
                rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)
                
                current_session["rag_chain"] = rag_chain
                current_session["rag_ready"] = True
                current_session["text_chunks"] = chunks
                
                st.success("‚úÖ PDF processed successfully!")
                st.rerun()
    
    # PDF Actions (only show if PDF is loaded)
    current_session = get_current_session()
    if current_session["rag_ready"]:
        st.subheader("üìä PDF Actions")
        
        # Download format selection
        download_format = st.selectbox(
            "üì• Download Format:",
            ["txt", "pdf", "pptx"],
            key="download_format"
        )
        
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üìÑ Generate Summary"):
                with st.spinner("Generating summary..."):
                    summary = generate_pdf_summary(current_session["text_chunks"])
                    filename = current_session["pdf_name"].replace(".pdf", "")
                    
                    if download_format == "txt":
                        st.download_button(
                            label="üíæ Download TXT",
                            data=summary,
                            file_name=f"{filename}_summary.txt",
                            mime="text/plain"
                        )
                    elif download_format == "pdf":
                        pdf_data = create_pdf(summary, filename)
                        st.download_button(
                            label="üíæ Download PDF",
                            data=pdf_data,
                            file_name=f"{filename}_summary.pdf",
                            mime="application/pdf"
                        )
                    elif download_format == "pptx":
                        pptx_data = create_pptx(summary, filename)
                        st.download_button(
                            label="üíæ Download PPTX",
                            data=pptx_data,
                            file_name=f"{filename}_summary.pptx",
                            mime="application/vnd.openxmlformats-officedocument.presentationml.presentation"
                        )
        
        with col2:
            if st.button("üîç Show NER"):
                if current_session["entities"]:
                    st.markdown("### Named Entities")
                    entity_display = format_entities_for_display(current_session["entities"])
                    st.markdown(entity_display)
    
    st.divider()
    
    # Session Management
    st.subheader("üí¨ Chat Sessions")
    
    # New Chat Button
    if st.button("‚ûï New Chat"):
        create_new_session("chat")
        st.rerun()
    
    # Display sessions
    for session_id in list(st.session_state.chat_sessions.keys()):
        session = st.session_state.chat_sessions[session_id]
        session_type = "üìÑ PDF" if session["session_type"] == "pdf" else "üí¨ Chat"
        session_name = f"{session_type} - {session_id}"
        
        if session["pdf_name"]:
            session_name = f"üìÑ {session['pdf_name'][:15]}... - {session_id[-8:]}"
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            if st.button(
                session_name,
                key=f"session_{session_id}",
                type="primary" if session_id == st.session_state.current_session_id else "secondary"
            ):
                st.session_state.current_session_id = session_id
                st.rerun()
        
        with col2:
            if st.button("üóëÔ∏è", key=f"delete_{session_id}"):
                delete_session(session_id)
                st.rerun()
    
    # Clear All Chats
    if st.button("üßπ Clear All Chats"):
        st.session_state.chat_sessions = {}
        create_new_session("chat")
        st.rerun()

# Main Chat Interface
current_session = get_current_session()
session_type_icon = "üìÑ" if current_session["session_type"] == "pdf" else "üí¨"

if current_session["pdf_name"]:
    st.title(f"{session_type_icon} PDF Chat - {current_session['pdf_name']}")
else:
    st.title(f"{session_type_icon} AI Chat Assistant")

# Display current model info
st.caption(f"Using: {st.session_state.selected_chat_model} | Session: {st.session_state.current_session_id[-8:]}")

# Display NER results if available
if current_session.get("entities"):
    with st.expander("üîç Named Entities Found", expanded=False):
        entity_display = format_entities_for_display(current_session["entities"])
        st.markdown(entity_display)

# Display chat messages
display_chat(current_session["messages"])

# Chat input
if current_session["rag_ready"]:
    prompt = st.chat_input("Ask a question about the uploaded PDF...")
    if prompt:
        # Add user message
        current_session["messages"].append(HumanMessage(content=prompt))
        st.chat_message("user").write(prompt)
        
        # Generate response
        with st.spinner("ü§î Thinking..."):
            result = current_session["rag_chain"].invoke(prompt)
            answer = result["result"]
            current_session["messages"].append(AIMessage(content=answer))
            st.chat_message("assistant").write(answer)
            st.rerun()

else:
    prompt = st.chat_input("Ask me anything...")
    if prompt:
        # Add user message
        current_session["messages"].append(HumanMessage(content=prompt))
        st.chat_message("user").write(prompt)
        
        # Generate response
        with st.spinner("ü§î Thinking..."):
            chat = ChatOpenAI(
                base_url=BASE_URL,
                api_key=API_KEY,
                temperature=0.7,
                model=st.session_state.selected_chat_model,
                http_client=client
            )

            class AgentState(TypedDict):
                messages: List[Union[HumanMessage, AIMessage, SystemMessage]]

            def first_node(state: AgentState) -> AgentState:
                response = chat.invoke(state["messages"])
                state["messages"].append(AIMessage(content=response.content))
                return state

            graph = StateGraph(AgentState)
            graph.add_node("node1", first_node)
            graph.add_edge(START, "node1")
            graph.add_edge("node1", END)
            agent = graph.compile()

            state_input = {"messages": current_session["messages"].copy()}
            result = agent.invoke(state_input)
            response = result["messages"][-1].content

            current_session["messages"].append(AIMessage(content=response))
            st.chat_message("assistant").write(response)
            st.rerun()
