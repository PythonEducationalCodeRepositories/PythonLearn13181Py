from typing import TypedDict, List, Union
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.graph import StateGraph, START, END
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.chains.retrieval_qa.base import RetrievalQA
from pdfplumber.high_level import extract_text
import tempfile
import os
import httpx
import tiktoken
import streamlit as st
from datetime import datetime
import json
from io import BytesIO
from pptx import Presentation
from pptx.util import Pt
from fpdf import FPDF
import spacy
import pandas as pd
from reportlab.lib.pagesizes import letter
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.lib.enums import TA_LEFT, TA_CENTER
from docx import Document
import docx2txt
import warnings
warnings.filterwarnings('ignore')

# Configuration Variables
API_KEY = "your-api-key-here"
BASE_URL = "https://your-base-url-here"

# Available Models List with their parameters
CHAT_MODELS = {
    "gpt-4o": {"max_tokens": 4096, "temperature": (0.0, 2.0), "top_p": (0.0, 1.0)},
    "gpt-4o-mini": {"max_tokens": 16384, "temperature": (0.0, 2.0), "top_p": (0.0, 1.0)},
    "gpt-4-turbo": {"max_tokens": 4096, "temperature": (0.0, 2.0), "top_p": (0.0, 1.0)},
    "gpt-4": {"max_tokens": 8192, "temperature": (0.0, 2.0), "top_p": (0.0, 1.0)},
    "gpt-3.5-turbo": {"max_tokens": 4096, "temperature": (0.0, 2.0), "top_p": (0.0, 1.0)},
    "text-davinci-003": {"max_tokens": 4097, "temperature": (0.0, 2.0), "top_p": (0.0, 1.0)},
    "your-custom-model-1": {"max_tokens": 4096, "temperature": (0.0, 2.0), "top_p": (0.0, 1.0)},
    "your-custom-model-2": {"max_tokens": 4096, "temperature": (0.0, 2.0), "top_p": (0.0, 1.0)}
}

EMBEDDING_MODELS = [
    "text-embedding-ada-002",
    "text-embedding-3-small", 
    "text-embedding-3-large",
    "your-custom-embedding-model"
]

# Configure
st.set_page_config(page_title='Document Chat Assistant', layout='wide')

tiktoken_cache_dir = "./token"
os.environ["TIKTOKEN_CACHE_DIR"] = tiktoken_cache_dir
client = httpx.Client(verify=False)

# Load NER model
@st.cache_resource
def load_ner_model():
    try:
        return spacy.load("en_core_web_sm")
    except IOError:
        st.warning("Install spaCy model: python -m spacy download en_core_web_sm")
        return None

nlp = load_ner_model()

# File processing functions
def extract_text_from_file(uploaded_file):
    """Extract text from various file formats"""
    file_extension = uploaded_file.name.split('.')[-1].lower()
    
    try:
        if file_extension == 'pdf':
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
                tmp.write(uploaded_file.read())
                return extract_text(tmp.name)
        
        elif file_extension in ['doc', 'docx']:
            with tempfile.NamedTemporaryFile(delete=False, suffix=f".{file_extension}") as tmp:
                tmp.write(uploaded_file.read())
                return docx2txt.process(tmp.name)
        
        elif file_extension == 'txt':
            return uploaded_file.read().decode('utf-8', errors='ignore')
        
        elif file_extension in ['xls', 'xlsx']:
            df_dict = pd.read_excel(uploaded_file, sheet_name=None)
            combined_text = ""
            for sheet_name, df in df_dict.items():
                combined_text += f"\n\nSheet: {sheet_name}\n"
                combined_text += df.to_string(index=False)
            return combined_text
        
        elif file_extension == 'csv':
            df = pd.read_csv(uploaded_file)
            return df.to_string(index=False)
        
        else:
            st.error(f"Unsupported file format: {file_extension}")
            return None
            
    except Exception as e:
        st.error(f"Error processing file: {str(e)}")
        return None

# File generation functions
def create_pptx(summary_text: str, filename: str) -> bytes:
    """Create PowerPoint file from text"""
    try:
        prs = Presentation()
        
        # Title slide
        title_slide_layout = prs.slide_layouts[0]
        slide = prs.slides.add_slide(title_slide_layout)
        title = slide.shapes.title
        subtitle = slide.placeholders[1]
        title.text = f"Summary: {filename}"
        subtitle.text = "AI Generated Summary"
        
        # Content slide
        bullet_slide_layout = prs.slide_layouts[1]
        slide = prs.slides.add_slide(bullet_slide_layout)
        shapes = slide.shapes
        title_shape = shapes.title
        body_shape = shapes.placeholders[1]
        
        title_shape.text = "Key Points"
        tf = body_shape.text_frame
        tf.clear()
        
        # Add bullet points
        lines = [line.strip() for line in summary_text.split('\n') if line.strip()]
        for i, line in enumerate(lines[:10]):
            if i == 0:
                tf.text = line
            else:
                p = tf.add_paragraph()
                p.text = line
                p.level = 0
                p.font.size = Pt(14)
        
        # Save to bytes
        pptx_io = BytesIO()
        prs.save(pptx_io)
        pptx_io.seek(0)
        return pptx_io.read()
    except Exception as e:
        st.error(f"Error creating PowerPoint: {str(e)}")
        return None

def create_pdf(text: str, filename: str) -> bytes:
    """Create PDF file from text"""
    try:
        pdf = FPDF()
        pdf.add_page()
        pdf.set_auto_page_break(auto=True, margin=15)
        
        # Title
        pdf.set_font("Arial", 'B', 16)
        pdf.cell(0, 10, f'Summary: {filename}', ln=True, align='C')
        pdf.ln(10)
        
        # Content
        pdf.set_font("Arial", size=12)
        for line in text.split('\n'):
            if line.strip():
                try:
                    pdf.multi_cell(0, 8, line.strip())
                except UnicodeEncodeError:
                    clean_line = line.encode('ascii', 'ignore').decode('ascii')
                    pdf.multi_cell(0, 8, clean_line)
                pdf.ln(2)
        
        pdf_output = BytesIO()
        pdf.output(pdf_output)
        pdf_output.seek(0)
        return pdf_output.read()
    except Exception as e:
        st.error(f"Error creating PDF: {str(e)}")
        return None

def create_word_doc(text: str, filename: str) -> bytes:
    """Create Word document from text"""
    try:
        doc = Document()
        
        # Add title
        title = doc.add_heading(f'Summary: {filename}', 0)
        
        # Add content
        for line in text.split('\n'):
            if line.strip():
                doc.add_paragraph(line.strip())
        
        # Save to BytesIO
        doc_io = BytesIO()
        doc.save(doc_io)
        doc_io.seek(0)
        return doc_io.read()
    except Exception as e:
        st.error(f"Error creating Word document: {str(e)}")
        return None

def create_chat_session_pdf(messages: List, session_name: str) -> bytes:
    """Create PDF from chat session"""
    try:
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=letter)
        styles = getSampleStyleSheet()
        story = []
        
        # Title
        title_style = ParagraphStyle(
            'CustomTitle',
            parent=styles['Heading1'],
            fontSize=18,
            spaceAfter=30,
            alignment=TA_CENTER
        )
        story.append(Paragraph(f"Chat Session: {session_name}", title_style))
        story.append(Spacer(1, 12))
        
        # Messages
        user_style = ParagraphStyle(
            'UserStyle',
            parent=styles['Normal'],
            fontSize=11,
            leftIndent=20,
            spaceAfter=10,
            alignment=TA_LEFT
        )
        
        bot_style = ParagraphStyle(
            'BotStyle',
            parent=styles['Normal'],
            fontSize=11,
            leftIndent=20,
            spaceAfter=10,
            alignment=TA_LEFT
        )
        
        for msg in messages[1:]:  # Skip system message
            try:
                if isinstance(msg, HumanMessage):
                    clean_content = msg.content.encode('ascii', 'ignore').decode('ascii')
                    story.append(Paragraph(f"ğŸ‘¤ USER: {clean_content}", user_style))
                elif isinstance(msg, AIMessage):
                    clean_content = msg.content.encode('ascii', 'ignore').decode('ascii')
                    story.append(Paragraph(f"ğŸ¤– ASSISTANT: {clean_content}", bot_style))
                story.append(Spacer(1, 6))
            except Exception:
                continue
        
        # Generate timestamp
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        story.append(Spacer(1, 20))
        story.append(Paragraph(f"Generated on: {timestamp}", styles['Normal']))
        
        doc.build(story)
        buffer.seek(0)
        return buffer.read()
    except Exception as e:
        st.error(f"Error creating chat PDF: {str(e)}")
        return None

def extract_entities(text: str) -> dict:
    """Extract named entities using spaCy NER"""
    if not nlp or not text:
        return {}
    
    try:
        doc = nlp(text)
        entities = {}
        
        for ent in doc.ents:
            if ent.label_ not in entities:
                entities[ent.label_] = []
            if ent.text not in entities[ent.label_]:
                entities[ent.label_].append(ent.text)
        
        return entities
    except Exception:
        return {}

def format_entities_for_display(entities: dict) -> str:
    """Format entities for display"""
    if not entities:
        return "No entities found."
    
    formatted = "## Named Entities:\n\n"
    
    entity_labels = {
        'PERSON': 'ğŸ‘¤ People',
        'ORG': 'ğŸ¢ Organizations', 
        'GPE': 'ğŸŒ Places',
        'MONEY': 'ğŸ’° Money',
        'DATE': 'ğŸ“… Dates',
        'TIME': 'â° Times',
        'PRODUCT': 'ğŸ“¦ Products',
        'EVENT': 'ğŸ‰ Events'
    }
    
    for label, items in entities.items():
        display_label = entity_labels.get(label, f'ğŸ“‹ {label}')
        formatted += f"**{display_label}:**\n"
        for item in items[:5]:
            formatted += f"- {item}\n"
        formatted += "\n"
    
    return formatted

# Initialize session state
def initialize_session_state():
    if "chat_sessions" not in st.session_state:
        st.session_state.chat_sessions = {}
    
    if "current_session_id" not in st.session_state:
        session_id = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        st.session_state.current_session_id = session_id
        st.session_state.chat_sessions[session_id] = {
            "messages": [SystemMessage(content="You are a helpful assistant.")],
            "rag_chain": None,
            "rag_ready": False,
            "file_name": None,
            "file_type": None,
            "session_type": "chat",
            "text_chunks": None,
            "entities": None
        }
    
    if "selected_chat_model" not in st.session_state:
        st.session_state.selected_chat_model = list(CHAT_MODELS.keys())[0]
    
    if "selected_embedding_model" not in st.session_state:
        st.session_state.selected_embedding_model = EMBEDDING_MODELS[0]
    
    # Model parameters
    if "model_temperature" not in st.session_state:
        st.session_state.model_temperature = 0.7
    
    if "model_max_tokens" not in st.session_state:
        st.session_state.model_max_tokens = 1000
    
    if "model_top_p" not in st.session_state:
        st.session_state.model_top_p = 1.0

def get_current_session():
    return st.session_state.chat_sessions[st.session_state.current_session_id]

def create_new_session(session_type="chat"):
    session_id = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    st.session_state.chat_sessions[session_id] = {
        "messages": [SystemMessage(content="You are a helpful assistant.")],
        "rag_chain": None,
        "rag_ready": False,
        "file_name": None,
        "file_type": None,
        "session_type": session_type,
        "text_chunks": None,
        "entities": None
    }
    st.session_state.current_session_id = session_id
    return session_id

def delete_session(session_id):
    if len(st.session_state.chat_sessions) > 1:
        del st.session_state.chat_sessions[session_id]
        if st.session_state.current_session_id == session_id:
            st.session_state.current_session_id = list(st.session_state.chat_sessions.keys())[0]

def display_chat(messages: List[Union[HumanMessage, AIMessage, SystemMessage]]):
    for msg in messages[1:]:  # Skip system message
        if isinstance(msg, HumanMessage):
            st.chat_message("user").write(msg.content)
        elif isinstance(msg, AIMessage):
            st.chat_message("assistant").write(msg.content)

def generate_document_summary(text_chunks):
    try:
        chat = ChatOpenAI(
            base_url=BASE_URL,
            api_key=API_KEY,
            model=st.session_state.selected_chat_model,
            temperature=st.session_state.model_temperature,
            max_tokens=st.session_state.model_max_tokens,
            top_p=st.session_state.model_top_p,
            http_client=client
        )
        
        combined_text = "\n".join(text_chunks[:15])
        summary_prompt = f"Provide a comprehensive summary of the following document:\n\n{combined_text}"
        
        response = chat.invoke([HumanMessage(content=summary_prompt)])
        return response.content
    except Exception as e:
        return f"Error generating summary: {str(e)}"

# Initialize
initialize_session_state()

# Sidebar
with st.sidebar:
    st.title("ğŸ¤– Document Chat Assistant")
    
    # Model Settings
    st.subheader("ğŸ› ï¸ Model Settings")
    st.session_state.selected_chat_model = st.selectbox(
        "Chat Model:",
        list(CHAT_MODELS.keys()),
        index=list(CHAT_MODELS.keys()).index(st.session_state.selected_chat_model)
    )
    
    st.session_state.selected_embedding_model = st.selectbox(
        "Embedding Model:",
        EMBEDDING_MODELS,
        index=EMBEDDING_MODELS.index(st.session_state.selected_embedding_model)
    )
    
    # Model Parameters
    st.subheader("âš™ï¸ Parameters")
    current_model_config = CHAT_MODELS[st.session_state.selected_chat_model]
    
    st.session_state.model_temperature = st.slider(
        "Temperature:",
        min_value=current_model_config["temperature"][0],
        max_value=current_model_config["temperature"][1],
        value=st.session_state.model_temperature,
        step=0.1,
        help="Controls randomness"
    )
    
    st.session_state.model_max_tokens = st.slider(
        "Max Tokens:",
        min_value=100,
        max_value=current_model_config["max_tokens"],
        value=min(st.session_state.model_max_tokens, current_model_config["max_tokens"]),
        step=100,
        help="Maximum response length"
    )
    
    if "top_p" in current_model_config:
        st.session_state.model_top_p = st.slider(
            "Top P:",
            min_value=current_model_config["top_p"][0],
            max_value=current_model_config["top_p"][1],
            value=st.session_state.model_top_p,
            step=0.1,
            help="Controls diversity"
        )
    
    st.divider()
    
    # File Upload
    st.subheader("ğŸ“„ Upload Document")
    st.info("ğŸ“ PDF â€¢ Word â€¢ Excel â€¢ CSV â€¢ TXT")
    
    uploaded_file = st.file_uploader(
        "Choose file", 
        type=["pdf", "docx", "doc", "txt", "xlsx", "xls", "csv"]
    )
    
    if uploaded_file:
        if st.button("ğŸš€ Process Document"):
            create_new_session("document")
            current_session = get_current_session()
            current_session["file_name"] = uploaded_file.name
            current_session["file_type"] = uploaded_file.name.split('.')[-1].lower()
            
            with st.spinner("Processing document..."):
                try:
                    raw_text = extract_text_from_file(uploaded_file)
                    
                    if raw_text:
                        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
                        chunks = text_splitter.split_text(raw_text)
                        
                        entities = extract_entities(raw_text)
                        current_session["entities"] = entities
                        
                        embedding_model = OpenAIEmbeddings(
                            base_url=BASE_URL,
                            model=st.session_state.selected_embedding_model,
                            api_key=API_KEY,
                            http_client=client
                        )
                        
                        vectordb = Chroma.from_texts(chunks, embedding_model, persist_directory="./chroma_index")
                        vectordb.persist()
                        
                        llm = ChatOpenAI(
                            base_url=BASE_URL,
                            model=st.session_state.selected_chat_model,
                            api_key=API_KEY,
                            temperature=st.session_state.model_temperature,
                            max_tokens=st.session_state.model_max_tokens,
                            top_p=st.session_state.model_top_p,
                            http_client=client
                        )
                        
                        retriever = vectordb.as_retriever()
                        rag_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, return_source_documents=True)
                        
                        current_session["rag_chain"] = rag_chain
                        current_session["rag_ready"] = True
                        current_session["text_chunks"] = chunks
                        
                        st.success("âœ… Document processed!")
                        st.rerun()
                    else:
                        st.error("Failed to extract text")
                        
                except Exception as e:
                    st.error(f"Processing error: {str(e)}")
    
    # Document Actions
    current_session = get_current_session()
    if current_session["rag_ready"]:
        st.subheader("ğŸ“Š Actions")
        
        download_format = st.selectbox(
            "Summary Format:",
            ["txt", "pdf", "docx", "pptx"]
        )
        
        if st.button("ğŸ“„ Generate Summary"):
            with st.spinner("Generating..."):
                summary = generate_document_summary(current_session["text_chunks"])
                filename = current_session["file_name"].rsplit('.', 1)[0]
                
                if download_format == "txt":
                    st.download_button(
                        "ğŸ’¾ Download TXT",
                        data=summary,
                        file_name=f"{filename}_summary.txt",
                        mime="text/plain"
                    )
                elif download_format == "pdf":
                    pdf_data = create_pdf(summary, filename)
                    if pdf_data:
                        st.download_button(
                            "ğŸ’¾ Download PDF",
                            data=pdf_data,
                            file_name=f"{filename}_summary.pdf",
                            mime="application/pdf"
                        )
                elif download_format == "docx":
                    word_data = create_word_doc(summary, filename)
                    if word_data:
                        st.download_button(
                            "ğŸ’¾ Download Word",
                            data=word_data,
                            file_name=f"{filename}_summary.docx",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                        )
                elif download_format == "pptx":
                    pptx_data = create_pptx(summary, filename)
                    if pptx_data:
                        st.download_button(
                            "ğŸ’¾ Download PPTX",
                            data=pptx_data,
                            file_name=f"{filename}_summary.pptx",
                            mime="application/vnd.openxmlformats-officedocument.presentationml.presentation"
                        )
        
        if st.button("ğŸ” Show Entities"):
            if current_session["entities"]:
                entity_display = format_entities_for_display(current_session["entities"])
                st.markdown(entity_display)
    
    st.divider()
    
    # Chat Sessions
    st.subheader("ğŸ’¬ Sessions")
    
    if st.button("â• New Chat"):
        create_new_session("chat")
        st.rerun()
    
    # Display sessions with download and delete buttons side by side
    for session_id in list(st.session_state.chat_sessions.keys()):
        session = st.session_state.chat_sessions[session_id]
        session_type = "ğŸ“„" if session["session_type"] == "document" else "ğŸ’¬"
        
        if session["file_name"]:
            session_name = f"{session_type} {session['file_name'][:10]}..."
        else:
            session_name = f"{session_type} Chat {session_id[-8:]}"
        
        col1, col2, col3 = st.columns([3, 1, 1])
        
        with col1:
            if st.button(
                session_name,
                key=f"session_{session_id}",
                type="primary" if session_id == st.session_state.current_session_id else "secondary",
                use_container_width=True
            ):
                st.session_state.current_session_id = session_id
                st.rerun()
        
        with col2:
            # Download button
            session_data = st.session_state.chat_sessions[session_id]
            pdf_data = create_chat_session_pdf(session_data["messages"], session_name)
            if pdf_data:
                st.download_button(
                    "ğŸ“¥",
                    data=pdf_data,
                    file_name=f"chat_{session_id[-8:]}.pdf",
                    mime="application/pdf",
                    key=f"download_{session_id}",
                    help="Download chat history"
                )
        
        with col3:
            if st.button("ğŸ—‘ï¸", key=f"delete_{session_id}", help="Delete session"):
                delete_session(session_id)
                st.rerun()
    
    if st.button("ğŸ§¹ Clear All"):
        st.session_state.chat_sessions = {}
        create_new_session("chat")
        st.rerun()

# Main Interface
current_session = get_current_session()
session_icon = "ğŸ“„" if current_session["session_type"] == "document" else "ğŸ’¬"

if current_session["file_name"]:
    st.title(f"{session_icon} Chat - {current_session['file_name']}")
else:
    st.title(f"{session_icon} AI Assistant")

# Model info
st.caption(f"ğŸ”§ {st.session_state.selected_chat_model} | ğŸŒ¡ï¸ {st.session_state.model_temperature} | ğŸ“Š {st.session_state.model_max_tokens} tokens")

# Show entities
if current_session.get("entities"):
    with st.expander("ğŸ” Entities", expanded=False):
        st.markdown(format_entities_for_display(current_session["entities"]))

# Display chat
display_chat(current_session["messages"])

# Chat input
if current_session["rag_ready"]:
    prompt = st.chat_input("Ask about your document...")
    if prompt:
        current_session["messages"].append(HumanMessage(content=prompt))
        st.chat_message("user").write(prompt)
        
        with st.spinner("ğŸ¤” Thinking..."):
            try:
                result = current_session["rag_chain"].invoke(prompt)
                answer = result["result"]
                current_session["messages"].append(AIMessage(content=answer))
                st.chat_message("assistant").write(answer)
                st.rerun()
            except Exception as e:
                error_msg = f"Error: {str(e)}"
                current_session["messages"].append(AIMessage(content=error_msg))
                st.chat_message("assistant").write(error_msg)
                st.rerun()
else:
    prompt = st.chat_input("Ask me anything...")
    if prompt:
        current_session["messages"].append(HumanMessage(content=prompt))
        st.chat_message("user").write(prompt)
        
        with st.spinner("ğŸ¤” Thinking..."):
            try:
                chat = ChatOpenAI(
                    base_url=BASE_URL,
                    api_key=API_KEY,
                    temperature=st.session_state.model_temperature,
                    max_tokens=st.session_state.model_max_tokens,
                    top_p=st.session_state.model_top_p,
                    model=st.session_state.selected_chat_model,
                    http_client=client
                )

                class AgentState(TypedDict):
                    messages: List[Union[HumanMessage, AIMessage, SystemMessage]]

                def first_node(state: AgentState) -> AgentState:
                    response = chat.invoke(state["messages"])
                    state["messages"].append(AIMessage(content=response.content))
                    return state

                graph = StateGraph(AgentState)
                graph.add_node("node1", first_node)
                graph.add_edge(START, "node1")
                graph.add_edge("node1", END)
                agent = graph.compile()

                state_input = {"messages": current_session["messages"].copy()}
                result = agent.invoke(state_input)
                response = result["messages"][-1].content

                current_session["messages"].append(AIMessage(content=response))
                st.chat_message("assistant").write(response)
                st.rerun()
                
            except Exception as e:
                error_msg = f"Error: {str(e)}"
                current_session["messages"].append(AIMessage(content=error_msg))
                st.chat_message("assistant").write(error_msg)
                st.rerun()

# Footer
st.divider()
st.caption("ğŸ’¡ Upload documents â€¢ Generate summaries â€¢ Chat with AI â€¢ Download chat history")
